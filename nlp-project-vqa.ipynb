{"metadata": {"kernelspec": {"name": "mindspore-python3.7-aarch64", "display_name": "MindSpore-python3.7-aarch64", "language": "python"}, "language_info": {"name": "python", "version": "3.7.6", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}, "vscode": {"interpreter": {"hash": "3a53c88f4fdc719dd3265ddb13e8e9d7137a6cb76512705960f4604c66fa0a8c"}}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "markdown", "source": "# nlp-project-vqa\n", "metadata": {}}, {"cell_type": "code", "source": "obs_path = \"s3://howie-zju/nlp/nlp_project_vqa/nlp-project-vqa/\" # howie's path\n# obs_path = \"s3://nlp-haofeng/nlp_proje|ct_vqa/\" # hy's path\n# obs_path = \"s3://nlp-haofeng/nlp_project_vqa/\" # zc's path\n# obs_path = \"s3://nlp-haofeng/nlp_project_vqa/\" # ct's path", "metadata": {"trusted": true}, "execution_count": 1, "outputs": []}, {"cell_type": "code", "source": "import moxing as mox\nmox.file.copy_parallel(src_url=obs_path+\"mindrecord\", dst_url='./mindrecord') \nmox.file.copy_parallel(src_url=obs_path+\"preprocess\", dst_url='./preprocess')\nmox.file.copy_parallel(src_url=obs_path+\"utils\",      dst_url='./utils')\nmox.file.copy_parallel(src_url=obs_path+\"model\",      dst_url='./model')\nmox.file.copy_parallel(src_url=obs_path+\"ckpt\",       dst_url='./ckpt')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/VGG.py\", dst_url='./pretrained/VGG.py')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/glove.6B.200d.word2vec.txt\", dst_url='./pretrained/glove.6B.200d.word2vec.txt')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/embeddings.py\", dst_url='./pretrained/embeddings.py')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/__init__.py\", dst_url='./pretrained/__init__.py')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map1.npy\", dst_url='./pretrained/feature_map1.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map2.npy\", dst_url='./pretrained/feature_map2.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map3.npy\", dst_url='./pretrained/feature_map3.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map4.npy\", dst_url='./pretrained/feature_map4.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map5.npy\", dst_url='./pretrained/feature_map5.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map6.npy\", dst_url='./pretrained/feature_map6.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map7.npy\", dst_url='./pretrained/feature_map7.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map8.npy\", dst_url='./pretrained/feature_map8.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map9.npy\", dst_url='./pretrained/feature_map9.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map10.npy\", dst_url='./pretrained/feature_map10.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map11.npy\", dst_url='./pretrained/feature_map11.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map12.npy\", dst_url='./pretrained/feature_map12.npy')\nmox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map13.npy\", dst_url='./pretrained/feature_map13.npy')\n# mox.file.copy_parallel(src_url=obs_path+\"data\",       dst_url='./data')", "metadata": {"trusted": true}, "execution_count": 2, "outputs": [{"name": "stderr", "text": "INFO:root:Using MoXing-v2.0.0.rc2.4b57a67b-4b57a67b\nINFO:root:Using OBS-Python-SDK-3.20.9.1\n", "output_type": "stream"}, {"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)", "\u001b[0;32m<ipython-input-2-7437882cdb0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mmox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"pretrained/feature_map6.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./pretrained/feature_map6.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mmox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"pretrained/feature_map7.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./pretrained/feature_map7.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mmox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"pretrained/feature_map8.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./pretrained/feature_map8.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0mmox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"pretrained/feature_map9.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./pretrained/feature_map9.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mmox\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_parallel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobs_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"pretrained/feature_map10.npy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_url\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'./pretrained/feature_map10.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/moxing/framework/file/file_io.py\u001b[0m in \u001b[0;36mcopy_parallel\u001b[0;34m(src_url, dst_url, file_list, threads, is_processing, use_queue, atom, skip_not_found)\u001b[0m\n\u001b[1;32m   2003\u001b[0m   \"\"\"\n\u001b[1;32m   2004\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_directory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2005\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0matom\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0matom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2006\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2007\u001b[0m   \u001b[0msrc_local\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_format_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc_url\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/moxing/framework/util/runtime.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/moxing/framework/file/file_io.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'skip file not found: %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/moxing/framework/file/file_io.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(src_url, dst_url, client_id, atom)\u001b[0m\n\u001b[1;32m   1718\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msrc_local\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdst_local\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1719\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0matom\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1720\u001b[0;31m         \u001b[0m_download_obs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_bucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_object_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_object_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1721\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m         \u001b[0m_download_obs_atom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_bucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc_object_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdst_object_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/moxing/framework/file/file_io.py\u001b[0m in \u001b[0;36m_download_obs\u001b[0;34m(obs_client, bucket_name, object_key, local_file)\u001b[0m\n\u001b[1;32m   1748\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m     \u001b[0;31m# _retryable_call(obs_client, 'getObject', bucket_name, object_key, downloadPath=local_file)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1750\u001b[0;31m     \u001b[0m_download_obs_by_stream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_client\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbucket_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/moxing/framework/file/file_io.py\u001b[0m in \u001b[0;36m_download_obs_by_stream\u001b[0;34m(obs_client, bucket_name, object_key, local_file)\u001b[0m\n\u001b[1;32m   1787\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1789\u001b[0;31m           \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m       \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"], "ename": "OSError", "evalue": "[Errno 28] No space left on device", "output_type": "error"}]}, {"cell_type": "code", "source": "import mindspore\nimport numpy as np\nimport os\nfrom easydict import EasyDict\nfrom preprocess.preprocess import *\nos.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  # \u5141\u8bb8\u91cd\u590d\u8f7d\u5165lib\u6587\u4ef6", "metadata": {"trusted": true}, "execution_count": 3, "outputs": [{"name": "stderr", "text": "INFO:matplotlib.font_manager:generated new fontManager\n", "output_type": "stream"}]}, {"cell_type": "markdown", "source": "\u56fe\u6a21\u5f0f", "metadata": {}}, {"cell_type": "code", "source": "from mindspore import context\ncontext.set_context(mode=context.GRAPH_MODE)", "metadata": {"trusted": true}, "execution_count": 4, "outputs": []}, {"cell_type": "markdown", "source": "PyNative\u6a21\u5f0f", "metadata": {}}, {"cell_type": "code", "source": "from mindspore import context\ncontext.set_context(mode=context.PYNATIVE_MODE)", "metadata": {}, "execution_count": 4, "outputs": []}, {"cell_type": "markdown", "source": "Ascend \u73af\u5883\u5b89\u88c5 MindSpore Hub", "metadata": {}}, {"cell_type": "code", "source": "! pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.3.0/Hub/any/mindspore_hub-1.3.0-py3-none-any.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "import mindspore_hub as mshub\nfrom mindspore import context\n\ncontext.set_context(mode=context.GRAPH_MODE,\n                    device_target=\"Ascend\",\n                    device_id=0)\n\nmodel = \"mindspore/ascend/1.3/vgg16_cifar10\"\nnetwork = mshub.load(model)\nnetwork.set_train(False)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## 1 \u9884\u5904\u7406", "metadata": {}}, {"cell_type": "markdown", "source": "### 1.1 \u9884\u5904\u7406\u914d\u7f6e", "metadata": {}}, {"cell_type": "code", "source": "padding = '<pad>'\nconfig = EasyDict({\n\t'train_img_path': './data/images/train/COCO_train2014_',\n\t'train_ans_path': './data/annotations/train.json',\n\t'train_que_path': './data/questions/train.json',\n\t'valid_img_path': './data/images/val/COCO_val2014_',\n\t'valid_ans_path': './data/annotations/val.json',\n\t'valid_que_path': './data/questions/val.json',\n\t'test_img_path': './data/images/test/COCO_val2014_',\n\t'test_ans_path':  './data/annotations/test.json',\n\t'test_que_path':  './data/questions/test.json',\n\t'max_length': 25,\n\t'dict_path': './mindrecord/dict.npy',\n\t'idx_word_dict_path': './mindrecord/idx_word_dict.npy',\n\t'filter_set_path': './mindrecord/',\n\t'pretrained_path': './pretrained/',\n\t'num_splits': 1,\n\t'train_mindrecord_path': './mindrecord/train.mindrecord',\n\t'valid_mindrecord_path': './mindrecord/valid.mindrecord',\n\t'test_mindrecord_path':  './mindrecord/test.mindrecord',\n})", "metadata": {"trusted": true}, "execution_count": 5, "outputs": []}, {"cell_type": "markdown", "source": "### 1.2 \u8bfb\u53d6\u6570\u636e", "metadata": {}}, {"cell_type": "markdown", "source": "\u6ce8: \u53ea\u53d6\u90a3\u4e9b\u7b54\u6848\u957f\u5ea6\u4e3a1\u7684vqa\u7ec4\u5408", "metadata": {}}, {"cell_type": "code", "source": "# get 3 types of input data\ntrain_images, train_questions, train_answers, train_options = get_list(config.train_que_path, config.train_ans_path)\nvalid_images, valid_questions, valid_answers, valid_options = get_list(config.valid_que_path, config.valid_ans_path)\ntest_images,  test_questions,  test_answers, test_options  = get_list(config.test_que_path,  config.test_ans_path)", "metadata": {}, "execution_count": 27, "outputs": []}, {"cell_type": "code", "source": "total_questions = train_questions + valid_questions + test_questions\ntotal_answers   = train_answers + valid_answers + test_answers\ntotal_options   = train_options + valid_options + test_options", "metadata": {}, "execution_count": 28, "outputs": []}, {"cell_type": "code", "source": "import numpy as np\nnp.array(train_options).shape", "metadata": {}, "execution_count": 29, "outputs": [{"execution_count": 29, "output_type": "execute_result", "data": {"text/plain": "(44375, 10)"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "### 1.3 \u6784\u5efa\u8bcd\u5178", "metadata": {}}, {"cell_type": "code", "source": "# build word vocab\nword_dict = dict({'<pad>': 0})\nword_dict = add_word_into_dict(total_questions, word_dict)\nword_dict = add_word_into_dict(total_options, word_dict)\n\nanswer_dict = dict()\nanswer_dict = add_answer_into_dict(total_answers, answer_dict)", "metadata": {}, "execution_count": 30, "outputs": []}, {"cell_type": "code", "source": "# build revert dict\nidx_word_dict = dict()\nfor item in word_dict.items():\n\tidx_word_dict[item[1]] = item[0]", "metadata": {}, "execution_count": 31, "outputs": []}, {"cell_type": "code", "source": "len(answer_dict)", "metadata": {}, "execution_count": 32, "outputs": [{"execution_count": 32, "output_type": "execute_result", "data": {"text/plain": "8193"}, "metadata": {}}]}, {"cell_type": "code", "source": "# save dict\nnp.save(config.dict_path, word_dict)\nnp.save(config.idx_word_dict_path, idx_word_dict)", "metadata": {}, "execution_count": 33, "outputs": []}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"./mindrecord/dict.npy\", dst_url=obs_path+\"mindrecord/dict.npy\")\nmox.file.copy_parallel(src_url=\"./mindrecord/idx_word_dict.npy\", dst_url=obs_path+\"mindrecord/idx_word_dict.npy\") ", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "### 1.4 \u5411\u91cf\u5316 & \u8865\u9f50\u957f\u5ea6", "metadata": {}}, {"cell_type": "code", "source": "# word -> vector & padding\ntrain_questions_vec = get_vec_and_pad(train_questions, word_dict, config.max_length)\nvalid_questions_vec = get_vec_and_pad(valid_questions, word_dict, config.max_length)\ntest_questions_vec = get_vec_and_pad(test_questions, word_dict, config.max_length)\n\ntrain_options_vec = get_option_vec_and_pad(train_options, word_dict, 1)\nvalid_options_vec = get_option_vec_and_pad(valid_options, word_dict, 1)\ntest_options_vec = get_option_vec_and_pad(test_options, word_dict, 1)\n\ntrain_answers_vec, _, _, _ = get_answer_to_idx(train_answers, answer_dict)\nvalid_answers_vec, _, _, _ = get_answer_to_idx(valid_answers, answer_dict)\ntest_answers_vec, _, _, _ = get_answer_to_idx(test_answers, answer_dict)\n_, bool_set, num_set, other_set = get_answer_to_idx(total_answers, answer_dict)", "metadata": {}, "execution_count": 34, "outputs": []}, {"cell_type": "code", "source": "np.array(train_options_vec)", "metadata": {}, "execution_count": 13, "outputs": [{"execution_count": 13, "output_type": "execute_result", "data": {"text/plain": "array([[    3,     3,   241, ...,     3,     3,     3],\n       [ 2280,  2280,  2280, ...,  2280,  2280,  2280],\n       [ 4582,   405,  8566, ...,   126,  1027,  1027],\n       ...,\n       [ 1415,  1415,  2476, ...,  1415,  1415,  1415],\n       [  505,   505,   505, ...,   505, 33781,   505],\n       [ 2476,  2476,  2476, ...,  2476,  1415,  2476]])"}, "metadata": {}}]}, {"cell_type": "code", "source": "# \u4fdd\u5b58\u96c6\u5408\nnp.save(config.filter_set_path+'bool.npy', bool_set)\nnp.save(config.filter_set_path+'num.npy', num_set)\nnp.save(config.filter_set_path+'other.npy', other_set)", "metadata": {}, "execution_count": 13, "outputs": []}, {"cell_type": "code", "source": "train_answers", "metadata": {}, "execution_count": 15, "outputs": []}, {"cell_type": "code", "source": "len(other_set)", "metadata": {}, "execution_count": 14, "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "7864"}, "metadata": {}}]}, {"cell_type": "code", "source": "cnt = 0\nfor answer in total_answers:\n    # print(answer)\n    if answer_dict[answer] in other_set:\n        cnt += 1\ncnt", "metadata": {}, "execution_count": 14, "outputs": [{"execution_count": 14, "output_type": "execute_result", "data": {"text/plain": "43740"}, "metadata": {}}]}, {"cell_type": "code", "source": "len(total_answers)", "metadata": {}, "execution_count": 15, "outputs": [{"execution_count": 15, "output_type": "execute_result", "data": {"text/plain": "87245"}, "metadata": {}}]}, {"cell_type": "code", "source": "# train_answers_vec", "metadata": {}, "execution_count": 16, "outputs": []}, {"cell_type": "markdown", "source": "### 1.5 \u53d6\u9891\u7387\u8f83\u9ad8\u7684\u90a3\u4e9b\u8bcd\u5f97\u5230\u7b54\u6848\u8bcd\u96c6", "metadata": {}}, {"cell_type": "code", "source": "total_answers_vec = train_answers_vec + valid_answers_vec + test_answers_vec\nleast_2_set = get_filtered_answer_set(total_answers_vec, 2) # 2958\nleast_6_set = get_filtered_answer_set(total_answers_vec, 6) # 999", "metadata": {}, "execution_count": 35, "outputs": [{"name": "stdout", "output_type": "stream", "text": "0.9399965614075305\n0.8768410797180354\n"}]}, {"cell_type": "code", "source": "len(least_2_set)", "metadata": {}, "execution_count": 18, "outputs": [{"execution_count": 18, "output_type": "execute_result", "data": {"text/plain": "2958"}, "metadata": {}}]}, {"cell_type": "code", "source": "len(least_6_set)", "metadata": {}, "execution_count": 19, "outputs": [{"execution_count": 19, "output_type": "execute_result", "data": {"text/plain": "999"}, "metadata": {}}]}, {"cell_type": "code", "source": "# \u4fdd\u5b58\u96c6\u5408\nnp.save(config.filter_set_path+'min2.npy', least_2_set)\nnp.save(config.filter_set_path+'min6.npy', least_6_set)", "metadata": {}, "execution_count": 20, "outputs": []}, {"cell_type": "markdown", "source": "### 1.6 \u751f\u6210MindRecord", "metadata": {}}, {"cell_type": "markdown", "source": "train", "metadata": {}}, {"cell_type": "code", "source": "generate_mindrecord(config.train_mindrecord_path, config.train_img_path, config.num_splits, train_images, train_questions_vec, train_answers_vec, train_options_vec)", "metadata": {}, "execution_count": 21, "outputs": [{"name": "stdout", "output_type": "stream", "text": "train\n"}]}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"./mindrecord/train.mindrecord\",    dst_url=obs_path+\"mindrecord/train.mindrecord\") \nmox.file.copy_parallel(src_url=\"./mindrecord/train.mindrecord.db\", dst_url=obs_path+\"mindrecord/train.mindrecord.db\") ", "metadata": {}, "execution_count": 22, "outputs": []}, {"cell_type": "markdown", "source": "valid", "metadata": {}}, {"cell_type": "code", "source": "generate_mindrecord(config.valid_mindrecord_path, config.valid_img_path, config.num_splits, valid_images, valid_questions_vec, valid_answers_vec, valid_options_vec)", "metadata": {}, "execution_count": 18, "outputs": [{"name": "stdout", "output_type": "stream", "text": "valid\n"}]}, {"cell_type": "code", "source": "! ls mindrecord", "metadata": {}, "execution_count": 23, "outputs": [{"name": "stdout", "output_type": "stream", "text": "bool.npy\t   min2.npy  num.npy\t       train.mindrecord.db\ndict.npy\t   min5.npy  other.npy\t       valid.mindrecord\nidx_word_dict.npy  min6.npy  train.mindrecord  valid.mindrecord.db\n"}]}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"./mindrecord/valid.mindrecord\",    dst_url=obs_path+\"mindrecord/valid.mindrecord\") \nmox.file.copy_parallel(src_url=\"./mindrecord/valid.mindrecord.db\", dst_url=obs_path+\"mindrecord/valid.mindrecord.db\") ", "metadata": {}, "execution_count": 20, "outputs": []}, {"cell_type": "markdown", "source": "test", "metadata": {}}, {"cell_type": "code", "source": "generate_mindrecord(config.test_mindrecord_path, config.test_img_path, config.num_splits, test_images, test_questions_vec, test_answers_vec, test_options_vec)", "metadata": {}, "execution_count": 21, "outputs": [{"name": "stdout", "output_type": "stream", "text": "test\n"}]}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=\"./mindrecord/test.mindrecord\",    dst_url=obs_path+\"mindrecord/test.mindrecord\") \nmox.file.copy_parallel(src_url=\"./mindrecord/test.mindrecord.db\", dst_url=obs_path+\"mindrecord/test.mindrecord.db\") ", "metadata": {}, "execution_count": 22, "outputs": []}, {"cell_type": "markdown", "source": "## 2 \u52a0\u8f7d\u6570\u636e", "metadata": {}}, {"cell_type": "markdown", "source": "### 2.1 \u52a0\u8f7d\u8bcd\u5178\u3001\u96c6\u5408", "metadata": {}}, {"cell_type": "code", "source": "# load dict\nword_dict = np.load(config.dict_path, allow_pickle=True).item()\nidx_word_dict = np.load(config.idx_word_dict_path, allow_pickle=True).item()", "metadata": {"trusted": true}, "execution_count": 6, "outputs": []}, {"cell_type": "code", "source": "# load filter set\nleast_2_set = np.load(config.filter_set_path+'min2.npy', allow_pickle=True).item()\nleast_6_set = np.load(config.filter_set_path+'min6.npy', allow_pickle=True).item()\nbool_set = np.load(config.filter_set_path+'bool.npy', allow_pickle=True).item()\nnum_set = np.load(config.filter_set_path+'num.npy', allow_pickle=True).item()\nother_set = np.load(config.filter_set_path+'other.npy', allow_pickle=True).item()\nfeature_map1_set = np.load(config.pretrained_path+'feature_map1.npy', allow_pickle=True).item()\nfeature_map2_set = np.load(config.pretrained_path+'feature_map2.npy', allow_pickle=True).item()\nfeature_map3_set = np.load(config.pretrained_path+'feature_map3.npy', allow_pickle=True).item()\nfeature_map4_set = np.load(config.pretrained_path+'feature_map4.npy', allow_pickle=True).item()\nfeature_map5_set = np.load(config.pretrained_path+'feature_map5.npy', allow_pickle=True).item()\nfeature_map6_set = np.load(config.pretrained_path+'feature_map6.npy', allow_pickle=True).item()\nfeature_map7_set = np.load(config.pretrained_path+'feature_map7.npy', allow_pickle=True).item()\nfeature_map8_set = np.load(config.pretrained_path+'feature_map8.npy', allow_pickle=True).item()\nfeature_map9_set = np.load(config.pretrained_path+'feature_map9.npy', allow_pickle=True).item()\nfeature_map10_set = np.load(config.pretrained_path+'feature_map10.npy', allow_pickle=True).item()\nfeature_map11_set = np.load(config.pretrained_path+'feature_map11.npy', allow_pickle=True).item()\nfeature_map12_set = np.load(config.pretrained_path+'feature_map12.npy', allow_pickle=True).item()\nfeature_map13_set = np.load(config.pretrained_path+'feature_map13.npy', allow_pickle=True).item()", "metadata": {"trusted": true}, "execution_count": 7, "outputs": [{"traceback": ["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)", "\u001b[0;32m<ipython-input-7-1bca5a7b12cc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnum_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_set_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'num.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mother_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter_set_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'other.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfeature_map1_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'feature_map1.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfeature_map2_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'feature_map2.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mfeature_map3_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'feature_map3.npy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 428\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    429\u001b[0m         \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n", "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './pretrained/feature_map1.npy'"], "ename": "FileNotFoundError", "evalue": "[Errno 2] No such file or directory: './pretrained/feature_map1.npy'", "output_type": "error"}]}, {"cell_type": "code", "source": "a = feature_map1_set + feature_map2_set", "metadata": {}, "execution_count": 17, "outputs": [{"ename": "TypeError", "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'", "output_type": "error", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)", "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17480/3915686955.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfeature_map1_set\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mfeature_map2_set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"]}]}, {"cell_type": "code", "source": "# set -> dict\nleast_2_dict = set_to_dict(least_2_set)\nleast_6_dict = set_to_dict(least_6_set)\n\nbool_dict = set_to_dict(bool_set)\nnum_dict = set_to_dict(num_set)\nother_dict = set_to_dict(other_set)", "metadata": {}, "execution_count": 73, "outputs": []}, {"cell_type": "code", "source": "feature_map1_set\n\n# for key, value in feature_map1_set.items():\n#     print(key)\n#     print(value)\n#     print(value.shape)\n#     break\n\nleast_2_dict\n", "metadata": {}, "execution_count": 74, "outputs": [{"execution_count": 74, "output_type": "execute_result", "data": {"text/plain": "{0: 0,\n 1: 1,\n 2: 2,\n 3: 3,\n 4: 4,\n 5: 5,\n 6: 6,\n 7: 7,\n 9: 8,\n 10: 9,\n 11: 10,\n 12: 11,\n 13: 12,\n 14: 13,\n 15: 14,\n 16: 15,\n 17: 16,\n 19: 17,\n 20: 18,\n 22: 19,\n 23: 20,\n 25: 21,\n 26: 22,\n 27: 23,\n 28: 24,\n 29: 25,\n 30: 26,\n 31: 27,\n 32: 28,\n 33: 29,\n 34: 30,\n 35: 31,\n 36: 32,\n 37: 33,\n 38: 34,\n 39: 35,\n 40: 36,\n 41: 37,\n 42: 38,\n 43: 39,\n 44: 40,\n 45: 41,\n 46: 42,\n 47: 43,\n 48: 44,\n 49: 45,\n 50: 46,\n 51: 47,\n 52: 48,\n 54: 49,\n 55: 50,\n 56: 51,\n 57: 52,\n 58: 53,\n 59: 54,\n 60: 55,\n 61: 56,\n 63: 57,\n 64: 58,\n 65: 59,\n 66: 60,\n 67: 61,\n 70: 62,\n 72: 63,\n 73: 64,\n 74: 65,\n 75: 66,\n 76: 67,\n 77: 68,\n 78: 69,\n 79: 70,\n 80: 71,\n 81: 72,\n 82: 73,\n 83: 74,\n 84: 75,\n 85: 76,\n 86: 77,\n 89: 78,\n 90: 79,\n 91: 80,\n 92: 81,\n 94: 82,\n 95: 83,\n 96: 84,\n 97: 85,\n 98: 86,\n 100: 87,\n 102: 88,\n 103: 89,\n 105: 90,\n 106: 91,\n 108: 92,\n 109: 93,\n 110: 94,\n 111: 95,\n 112: 96,\n 114: 97,\n 115: 98,\n 116: 99,\n 117: 100,\n 118: 101,\n 119: 102,\n 120: 103,\n 121: 104,\n 122: 105,\n 123: 106,\n 124: 107,\n 126: 108,\n 127: 109,\n 128: 110,\n 129: 111,\n 130: 112,\n 131: 113,\n 132: 114,\n 133: 115,\n 134: 116,\n 135: 117,\n 136: 118,\n 137: 119,\n 138: 120,\n 139: 121,\n 141: 122,\n 143: 123,\n 145: 124,\n 146: 125,\n 147: 126,\n 149: 127,\n 151: 128,\n 152: 129,\n 153: 130,\n 154: 131,\n 155: 132,\n 156: 133,\n 158: 134,\n 159: 135,\n 160: 136,\n 161: 137,\n 166: 138,\n 167: 139,\n 169: 140,\n 170: 141,\n 171: 142,\n 172: 143,\n 173: 144,\n 174: 145,\n 175: 146,\n 176: 147,\n 177: 148,\n 178: 149,\n 179: 150,\n 180: 151,\n 181: 152,\n 182: 153,\n 183: 154,\n 184: 155,\n 185: 156,\n 189: 157,\n 190: 158,\n 191: 159,\n 192: 160,\n 194: 161,\n 195: 162,\n 196: 163,\n 197: 164,\n 198: 165,\n 199: 166,\n 203: 167,\n 204: 168,\n 205: 169,\n 208: 170,\n 209: 171,\n 210: 172,\n 211: 173,\n 212: 174,\n 214: 175,\n 215: 176,\n 216: 177,\n 217: 178,\n 218: 179,\n 219: 180,\n 220: 181,\n 221: 182,\n 222: 183,\n 225: 184,\n 226: 185,\n 228: 186,\n 231: 187,\n 233: 188,\n 234: 189,\n 237: 190,\n 238: 191,\n 239: 192,\n 240: 193,\n 241: 194,\n 242: 195,\n 243: 196,\n 244: 197,\n 245: 198,\n 248: 199,\n 249: 200,\n 250: 201,\n 251: 202,\n 252: 203,\n 254: 204,\n 255: 205,\n 256: 206,\n 257: 207,\n 258: 208,\n 259: 209,\n 260: 210,\n 261: 211,\n 262: 212,\n 263: 213,\n 264: 214,\n 266: 215,\n 267: 216,\n 268: 217,\n 269: 218,\n 270: 219,\n 272: 220,\n 273: 221,\n 275: 222,\n 276: 223,\n 277: 224,\n 278: 225,\n 279: 226,\n 280: 227,\n 281: 228,\n 282: 229,\n 283: 230,\n 284: 231,\n 285: 232,\n 286: 233,\n 287: 234,\n 290: 235,\n 291: 236,\n 292: 237,\n 294: 238,\n 295: 239,\n 296: 240,\n 297: 241,\n 298: 242,\n 299: 243,\n 300: 244,\n 301: 245,\n 302: 246,\n 304: 247,\n 305: 248,\n 306: 249,\n 307: 250,\n 308: 251,\n 309: 252,\n 310: 253,\n 311: 254,\n 312: 255,\n 314: 256,\n 315: 257,\n 316: 258,\n 317: 259,\n 318: 260,\n 319: 261,\n 320: 262,\n 321: 263,\n 322: 264,\n 323: 265,\n 324: 266,\n 325: 267,\n 326: 268,\n 327: 269,\n 332: 270,\n 333: 271,\n 334: 272,\n 335: 273,\n 336: 274,\n 337: 275,\n 338: 276,\n 339: 277,\n 341: 278,\n 342: 279,\n 343: 280,\n 344: 281,\n 345: 282,\n 346: 283,\n 347: 284,\n 348: 285,\n 349: 286,\n 350: 287,\n 351: 288,\n 352: 289,\n 354: 290,\n 356: 291,\n 357: 292,\n 359: 293,\n 360: 294,\n 362: 295,\n 363: 296,\n 364: 297,\n 366: 298,\n 367: 299,\n 368: 300,\n 369: 301,\n 370: 302,\n 371: 303,\n 373: 304,\n 374: 305,\n 375: 306,\n 377: 307,\n 378: 308,\n 379: 309,\n 380: 310,\n 381: 311,\n 383: 312,\n 384: 313,\n 385: 314,\n 387: 315,\n 388: 316,\n 389: 317,\n 391: 318,\n 392: 319,\n 393: 320,\n 394: 321,\n 395: 322,\n 397: 323,\n 400: 324,\n 402: 325,\n 403: 326,\n 404: 327,\n 405: 328,\n 407: 329,\n 408: 330,\n 409: 331,\n 410: 332,\n 411: 333,\n 412: 334,\n 414: 335,\n 415: 336,\n 416: 337,\n 417: 338,\n 419: 339,\n 420: 340,\n 421: 341,\n 423: 342,\n 424: 343,\n 426: 344,\n 428: 345,\n 431: 346,\n 433: 347,\n 434: 348,\n 435: 349,\n 436: 350,\n 437: 351,\n 440: 352,\n 441: 353,\n 442: 354,\n 443: 355,\n 445: 356,\n 446: 357,\n 447: 358,\n 448: 359,\n 449: 360,\n 450: 361,\n 451: 362,\n 453: 363,\n 454: 364,\n 455: 365,\n 456: 366,\n 457: 367,\n 458: 368,\n 459: 369,\n 460: 370,\n 461: 371,\n 462: 372,\n 463: 373,\n 465: 374,\n 466: 375,\n 467: 376,\n 468: 377,\n 470: 378,\n 473: 379,\n 474: 380,\n 475: 381,\n 476: 382,\n 477: 383,\n 478: 384,\n 479: 385,\n 480: 386,\n 481: 387,\n 482: 388,\n 483: 389,\n 484: 390,\n 485: 391,\n 486: 392,\n 488: 393,\n 489: 394,\n 490: 395,\n 491: 396,\n 492: 397,\n 493: 398,\n 498: 399,\n 499: 400,\n 500: 401,\n 501: 402,\n 502: 403,\n 503: 404,\n 504: 405,\n 505: 406,\n 506: 407,\n 509: 408,\n 510: 409,\n 511: 410,\n 512: 411,\n 514: 412,\n 515: 413,\n 516: 414,\n 517: 415,\n 518: 416,\n 519: 417,\n 520: 418,\n 521: 419,\n 522: 420,\n 523: 421,\n 524: 422,\n 525: 423,\n 527: 424,\n 528: 425,\n 529: 426,\n 530: 427,\n 531: 428,\n 532: 429,\n 533: 430,\n 534: 431,\n 535: 432,\n 537: 433,\n 540: 434,\n 541: 435,\n 542: 436,\n 543: 437,\n 544: 438,\n 545: 439,\n 546: 440,\n 548: 441,\n 549: 442,\n 550: 443,\n 551: 444,\n 552: 445,\n 553: 446,\n 554: 447,\n 558: 448,\n 559: 449,\n 561: 450,\n 562: 451,\n 563: 452,\n 564: 453,\n 565: 454,\n 567: 455,\n 569: 456,\n 570: 457,\n 571: 458,\n 572: 459,\n 573: 460,\n 574: 461,\n 578: 462,\n 579: 463,\n 581: 464,\n 582: 465,\n 583: 466,\n 584: 467,\n 585: 468,\n 587: 469,\n 590: 470,\n 591: 471,\n 592: 472,\n 593: 473,\n 597: 474,\n 598: 475,\n 599: 476,\n 600: 477,\n 601: 478,\n 602: 479,\n 603: 480,\n 604: 481,\n 608: 482,\n 609: 483,\n 611: 484,\n 612: 485,\n 613: 486,\n 614: 487,\n 615: 488,\n 617: 489,\n 618: 490,\n 619: 491,\n 620: 492,\n 621: 493,\n 622: 494,\n 625: 495,\n 628: 496,\n 629: 497,\n 630: 498,\n 632: 499,\n 635: 500,\n 636: 501,\n 637: 502,\n 638: 503,\n 639: 504,\n 640: 505,\n 641: 506,\n 645: 507,\n 646: 508,\n 648: 509,\n 649: 510,\n 650: 511,\n 652: 512,\n 653: 513,\n 654: 514,\n 657: 515,\n 658: 516,\n 660: 517,\n 661: 518,\n 662: 519,\n 665: 520,\n 667: 521,\n 668: 522,\n 669: 523,\n 670: 524,\n 671: 525,\n 672: 526,\n 673: 527,\n 674: 528,\n 675: 529,\n 677: 530,\n 679: 531,\n 683: 532,\n 684: 533,\n 685: 534,\n 687: 535,\n 688: 536,\n 689: 537,\n 690: 538,\n 692: 539,\n 693: 540,\n 694: 541,\n 695: 542,\n 700: 543,\n 701: 544,\n 703: 545,\n 706: 546,\n 707: 547,\n 709: 548,\n 711: 549,\n 715: 550,\n 716: 551,\n 717: 552,\n 718: 553,\n 720: 554,\n 722: 555,\n 723: 556,\n 724: 557,\n 725: 558,\n 728: 559,\n 729: 560,\n 730: 561,\n 731: 562,\n 734: 563,\n 735: 564,\n 736: 565,\n 739: 566,\n 740: 567,\n 741: 568,\n 742: 569,\n 744: 570,\n 745: 571,\n 746: 572,\n 747: 573,\n 748: 574,\n 749: 575,\n 750: 576,\n 752: 577,\n 753: 578,\n 754: 579,\n 755: 580,\n 756: 581,\n 758: 582,\n 759: 583,\n 760: 584,\n 762: 585,\n 763: 586,\n 764: 587,\n 765: 588,\n 768: 589,\n 771: 590,\n 773: 591,\n 774: 592,\n 775: 593,\n 776: 594,\n 782: 595,\n 783: 596,\n 784: 597,\n 789: 598,\n 791: 599,\n 792: 600,\n 793: 601,\n 794: 602,\n 795: 603,\n 796: 604,\n 798: 605,\n 799: 606,\n 800: 607,\n 803: 608,\n 805: 609,\n 806: 610,\n 809: 611,\n 810: 612,\n 811: 613,\n 812: 614,\n 813: 615,\n 814: 616,\n 815: 617,\n 816: 618,\n 817: 619,\n 819: 620,\n 820: 621,\n 821: 622,\n 822: 623,\n 824: 624,\n 825: 625,\n 827: 626,\n 828: 627,\n 829: 628,\n 830: 629,\n 831: 630,\n 833: 631,\n 834: 632,\n 835: 633,\n 837: 634,\n 838: 635,\n 841: 636,\n 843: 637,\n 844: 638,\n 845: 639,\n 846: 640,\n 847: 641,\n 848: 642,\n 850: 643,\n 851: 644,\n 852: 645,\n 853: 646,\n 854: 647,\n 855: 648,\n 856: 649,\n 857: 650,\n 860: 651,\n 863: 652,\n 864: 653,\n 866: 654,\n 867: 655,\n 868: 656,\n 870: 657,\n 873: 658,\n 874: 659,\n 875: 660,\n 876: 661,\n 877: 662,\n 878: 663,\n 879: 664,\n 880: 665,\n 881: 666,\n 882: 667,\n 883: 668,\n 884: 669,\n 885: 670,\n 886: 671,\n 887: 672,\n 889: 673,\n 890: 674,\n 891: 675,\n 892: 676,\n 894: 677,\n 895: 678,\n 896: 679,\n 897: 680,\n 898: 681,\n 899: 682,\n 900: 683,\n 901: 684,\n 903: 685,\n 904: 686,\n 906: 687,\n 907: 688,\n 909: 689,\n 910: 690,\n 911: 691,\n 913: 692,\n 915: 693,\n 916: 694,\n 917: 695,\n 918: 696,\n 919: 697,\n 922: 698,\n 923: 699,\n 931: 700,\n 932: 701,\n 934: 702,\n 936: 703,\n 937: 704,\n 938: 705,\n 939: 706,\n 940: 707,\n 941: 708,\n 943: 709,\n 945: 710,\n 946: 711,\n 948: 712,\n 949: 713,\n 951: 714,\n 954: 715,\n 955: 716,\n 956: 717,\n 957: 718,\n 958: 719,\n 959: 720,\n 962: 721,\n 963: 722,\n 964: 723,\n 966: 724,\n 969: 725,\n 972: 726,\n 974: 727,\n 976: 728,\n 980: 729,\n 981: 730,\n 985: 731,\n 986: 732,\n 987: 733,\n 988: 734,\n 990: 735,\n 991: 736,\n 992: 737,\n 996: 738,\n 997: 739,\n 998: 740,\n 999: 741,\n 1001: 742,\n 1002: 743,\n 1004: 744,\n 1005: 745,\n 1006: 746,\n 1007: 747,\n 1008: 748,\n 1009: 749,\n 1012: 750,\n 1013: 751,\n 1014: 752,\n 1015: 753,\n 1016: 754,\n 1017: 755,\n 1018: 756,\n 1020: 757,\n 1021: 758,\n 1024: 759,\n 1026: 760,\n 1027: 761,\n 1029: 762,\n 1030: 763,\n 1033: 764,\n 1035: 765,\n 1036: 766,\n 1038: 767,\n 1039: 768,\n 1040: 769,\n 1041: 770,\n 1042: 771,\n 1043: 772,\n 1044: 773,\n 1045: 774,\n 1047: 775,\n 1048: 776,\n 1049: 777,\n 1050: 778,\n 1051: 779,\n 1053: 780,\n 1055: 781,\n 1056: 782,\n 1058: 783,\n 1062: 784,\n 1063: 785,\n 1064: 786,\n 1065: 787,\n 1066: 788,\n 1067: 789,\n 1068: 790,\n 1073: 791,\n 1074: 792,\n 1076: 793,\n 1077: 794,\n 1078: 795,\n 1080: 796,\n 1083: 797,\n 1084: 798,\n 1087: 799,\n 1088: 800,\n 1089: 801,\n 1091: 802,\n 1092: 803,\n 1094: 804,\n 1097: 805,\n 1099: 806,\n 1104: 807,\n 1106: 808,\n 1107: 809,\n 1109: 810,\n 1112: 811,\n 1114: 812,\n 1115: 813,\n 1117: 814,\n 1119: 815,\n 1120: 816,\n 1121: 817,\n 1122: 818,\n 1123: 819,\n 1125: 820,\n 1126: 821,\n 1127: 822,\n 1130: 823,\n 1132: 824,\n 1133: 825,\n 1134: 826,\n 1135: 827,\n 1136: 828,\n 1138: 829,\n 1140: 830,\n 1141: 831,\n 1142: 832,\n 1146: 833,\n 1147: 834,\n 1148: 835,\n 1149: 836,\n 1150: 837,\n 1153: 838,\n 1154: 839,\n 1155: 840,\n 1156: 841,\n 1157: 842,\n 1159: 843,\n 1160: 844,\n 1163: 845,\n 1166: 846,\n 1167: 847,\n 1168: 848,\n 1171: 849,\n 1172: 850,\n 1173: 851,\n 1174: 852,\n 1175: 853,\n 1176: 854,\n 1177: 855,\n 1179: 856,\n 1180: 857,\n 1186: 858,\n 1187: 859,\n 1189: 860,\n 1190: 861,\n 1191: 862,\n 1193: 863,\n 1194: 864,\n 1197: 865,\n 1199: 866,\n 1201: 867,\n 1202: 868,\n 1205: 869,\n 1206: 870,\n 1208: 871,\n 1209: 872,\n 1210: 873,\n 1211: 874,\n 1212: 875,\n 1213: 876,\n 1214: 877,\n 1215: 878,\n 1216: 879,\n 1217: 880,\n 1218: 881,\n 1219: 882,\n 1221: 883,\n 1223: 884,\n 1228: 885,\n 1229: 886,\n 1230: 887,\n 1231: 888,\n 1232: 889,\n 1233: 890,\n 1234: 891,\n 1236: 892,\n 1238: 893,\n 1239: 894,\n 1242: 895,\n 1246: 896,\n 1248: 897,\n 1251: 898,\n 1252: 899,\n 1254: 900,\n 1257: 901,\n 1258: 902,\n 1259: 903,\n 1260: 904,\n 1261: 905,\n 1262: 906,\n 1263: 907,\n 1266: 908,\n 1267: 909,\n 1268: 910,\n 1269: 911,\n 1271: 912,\n 1272: 913,\n 1273: 914,\n 1274: 915,\n 1275: 916,\n 1276: 917,\n 1277: 918,\n 1278: 919,\n 1279: 920,\n 1282: 921,\n 1284: 922,\n 1285: 923,\n 1286: 924,\n 1287: 925,\n 1288: 926,\n 1289: 927,\n 1290: 928,\n 1292: 929,\n 1293: 930,\n 1294: 931,\n 1297: 932,\n 1302: 933,\n 1304: 934,\n 1307: 935,\n 1308: 936,\n 1310: 937,\n 1311: 938,\n 1314: 939,\n 1316: 940,\n 1317: 941,\n 1318: 942,\n 1320: 943,\n 1321: 944,\n 1323: 945,\n 1324: 946,\n 1325: 947,\n 1326: 948,\n 1327: 949,\n 1329: 950,\n 1330: 951,\n 1331: 952,\n 1332: 953,\n 1333: 954,\n 1335: 955,\n 1336: 956,\n 1337: 957,\n 1338: 958,\n 1339: 959,\n 1340: 960,\n 1341: 961,\n 1343: 962,\n 1345: 963,\n 1348: 964,\n 1349: 965,\n 1352: 966,\n 1353: 967,\n 1354: 968,\n 1358: 969,\n 1360: 970,\n 1362: 971,\n 1364: 972,\n 1368: 973,\n 1370: 974,\n 1372: 975,\n 1373: 976,\n 1374: 977,\n 1375: 978,\n 1376: 979,\n 1377: 980,\n 1379: 981,\n 1381: 982,\n 1384: 983,\n 1385: 984,\n 1386: 985,\n 1388: 986,\n 1389: 987,\n 1391: 988,\n 1393: 989,\n 1394: 990,\n 1395: 991,\n 1396: 992,\n 1397: 993,\n 1398: 994,\n 1399: 995,\n 1400: 996,\n 1401: 997,\n 1403: 998,\n 1405: 999,\n ...}"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "### 2.2 \u8bad\u7ec3\u914d\u7f6e", "metadata": {}}, {"cell_type": "code", "source": "# model_name = 'baseline'\n# model_name = 'stack_attention'\nmodel_name = 'topdown_attention'", "metadata": {}, "execution_count": 43, "outputs": []}, {"cell_type": "code", "source": "# batch_size = 32 # baseline\n# batch_size = 100 # stacked attention\nbatch_size = 128 # top-down attention", "metadata": {}, "execution_count": 44, "outputs": []}, {"cell_type": "code", "source": "! pip install gensim", "metadata": {}, "execution_count": 12, "outputs": [{"name": "stdout", "output_type": "stream", "text": "Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\nRequirement already satisfied: gensim in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (4.2.0)\nRequirement already satisfied: scipy>=0.18.1 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from gensim) (1.5.4)\nRequirement already satisfied: numpy>=1.17.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from gensim) (1.17.5)\nRequirement already satisfied: smart-open>=1.8.1 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from gensim) (6.0.0)\n"}]}, {"cell_type": "code", "source": "train_config = EasyDict({\n\t'model': model_name,\n\t'vocab_size': 52083,\n\t'output_size': 999 if model_name == 'baseline' or model_name == 'stack_attention' else 2958,\n\t'batch_size': batch_size,\n\t'epoch_size': 3,\n\t'max_length': 14,\n\t'use_op': False,\n\t'use_pretrained_feature_map': True,\n\t'hidden_size': 1024,\n\t'lr': 1e-4,\n\t'momentum': 0.9,\n\t'weight_decay': 3e-5,\n\t'early_stop': 100,\n\t'ckpt_save_path': './ckpt',\n\t'checkpoint_path': './ckpt/'+model_name+'.ckpt',\n\t'pretrained_path': './pretrained/vgg19_ascend_v130_imagenet2012_research_cv_top1acc74_top5acc91.97.ckpt',\n\t'embedding_table_path': './pretrained/embedding_table_glove_200d.txt',\n\t'glove_vector_path': './pretrained/glove.6B.200d.txt',\n\t'glove_word2vec_path': './pretrained/glove.6B.200d.word2vec.txt',\n})", "metadata": {}, "execution_count": 48, "outputs": []}, {"cell_type": "markdown", "source": "### 2.3 \u751f\u6210\u6570\u636e\u96c6", "metadata": {}}, {"cell_type": "code", "source": "# platform = 'Local'\n# platform = 'Colob'\nplatform = 'Ascend'", "metadata": {}, "execution_count": 49, "outputs": []}, {"cell_type": "code", "source": "# frequency filter dict\nfilter_dict = least_6_dict if model_name == 'baseline' or model_name == 'stack_attention' else least_2_dict\n# image size\nimage_width = 224 if model_name == 'baseline' else 448\nimage_height = 224 if model_name == 'baseline' else 448\n# parallel workers\nnum_parallel_workers = 4 if platform == 'Ascend' or platform == 'Local' else 2\nprint(num_parallel_workers)\n# create dataset\ntrain_dataset = generate_dataset(config.train_mindrecord_path, train_config.batch_size, 1, train_config.max_length, \n                                 filter_dict, image_height, image_width, num_parallel_workers)\nvalid_dataset = generate_dataset(config.valid_mindrecord_path, train_config.batch_size, 1, train_config.max_length, \n                                 filter_dict, image_height, image_width, num_parallel_workers)\ntest_dataset  = generate_dataset(config.test_mindrecord_path , train_config.batch_size, 1, train_config.max_length, \n                                 filter_dict, image_height, image_width, num_parallel_workers)", "metadata": {}, "execution_count": 60, "outputs": [{"name": "stdout", "output_type": "stream", "text": "4\n"}]}, {"cell_type": "markdown", "source": "## 3 \u8bad\u7ec3\u6a21\u578b", "metadata": {}}, {"cell_type": "markdown", "source": "### 3.1 \u521b\u5efa\u6a21\u578b", "metadata": {}}, {"cell_type": "code", "source": "import mindspore.nn as nn\nimport mindspore.ops.operations as P\nfrom utils.metric_utils import *\nfrom utils.wrapper_utils import *\nfrom utils.callback_utils import *", "metadata": {}, "execution_count": 62, "outputs": []}, {"cell_type": "code", "source": "class Network(nn.Cell):\n\tdef __init__(self, train_config):\n\t\tsuper(Network, self).__init__()\n\t\tself.reshape = P.Reshape()\n\t\tself.embedding = nn.Embedding(train_config.vocab_size, train_config.hidden_size)\n\t\tself.out = nn.Dense(train_config.hidden_size*train_config.max_length, train_config.output_size)\n\tdef construct(self, images, questions):\n\t\tx = self.embedding(questions)\n\t\tx = x.reshape(x.shape[0], -1)\n\t\tx = self.out(x)\n\t\treturn x", "metadata": {}, "execution_count": 63, "outputs": []}, {"cell_type": "code", "source": "from model.vqa_baseline import *\nfrom model.stack_attention import *\nfrom model.topdown_attention import *", "metadata": {}, "execution_count": 64, "outputs": []}, {"cell_type": "code", "source": "# \u521b\u5efa\u7f51\u7edc\nif model_name == 'baseline':\n\tif train_config.use_op:\n\t\tnetwork = VQABasicOpAttn(train_config)\n\telse:\n\t\tnetwork = VQABasic(train_config)\nelif model_name == 'stack_attention':\n\tif train_config.use_op:\n\t\tnetwork = StackedAttentionNetOpAttn(word_dict, train_config)\n\telse:\n\t\tnetwork = StackedAttentionNet(word_dict, train_config)\nelif model_name == 'topdown_attention':\n\tif train_config.use_op and train_config.use_pretrained_feature_map:\n\t\tnetwork = TopDownAttentionNetOpAttn(word_dict, train_config)\n\telif train_config.use_op:\n\t\tnetwork = TopDownAttentionNetOpAttn(word_dict, train_config)\n\telif train_config.use_pretrained_feature_map:\n\t\tnetwork = TopDownAttentionNetFeature(word_dict, train_config)\n\telse:\n\t\tnetwork = TopDownAttentionNet(word_dict, train_config)", "metadata": {}, "execution_count": 65, "outputs": []}, {"cell_type": "code", "source": "# questions = Tensor(np.zeros((32, 14), dtype=np.int32))\n# images = Tensor(np.zeros((32, 448, 448, 3), dtype=np.int8))\n# options = Tensor(np.zeros((32, 10), dtype=np.int32))\n# output = network(images, questions, options)\n# print(output)", "metadata": {}, "execution_count": 46, "outputs": []}, {"cell_type": "code", "source": "# \u521b\u5efa\u8bad\u7ec3\u3001\u6d4b\u8bd5\u7f51\u7edc\nloss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\n# train network\ntrain_net = TrainNetworkWrapper(network, loss_fn, train_config)\ntrain_net.set_train(True)\n# valid network\nvalid_net = WithEvalCellWrapper(network, train_config)\nvalid_net.set_train(False)", "metadata": {}, "execution_count": 66, "outputs": [{"execution_count": 66, "output_type": "execute_result", "data": {"text/plain": "WithEvalCellWrapper<\n  (network): TopDownAttentionNetFeature<\n    (text_net): TextFeatureCell<\n      (embeddings): Embedding<vocab_size=52083, embedding_size=200, use_one_hot=False, embedding_table=Parameter (name=text_net.embeddings.embedding_table, shape=(52083, 200), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n      >\n    (fc_feature): Dense<\n      input_channels=8192, output_channels=2048, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (topdown_attn): TopDownAttentionLayer<\n      (fc_attn_nonlin): Dense<\n        input_channels=2560, output_channels=512, activation=Tanh<>\n        (activation): Tanh<>\n        >\n      (fc_attn_lin): Dense<input_channels=512, output_channels=1>\n      >\n    (fc_questions): Dense<\n      input_channels=512, output_channels=512, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (fc_images): Dense<\n      input_channels=2048, output_channels=512, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (fc_f_t): Dense<\n      input_channels=512, output_channels=300, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (fc_f_i): Dense<\n      input_channels=512, output_channels=2048, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (fc_w_t): Dense<input_channels=300, output_channels=2958>\n    (fc_w_i): Dense<input_channels=2048, output_channels=2958>\n    >\n  (softmax): SoftmaxCrossEntropyWithLogits<>\n  (acc): Accuracy<>\n  >"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "### 3.2 \u5f00\u59cb\u8bad\u7ec3", "metadata": {}}, {"cell_type": "code", "source": "def train(train_net, valid_net, train_dataset, valid_dataset, train_config):\n\t# \u521b\u5efa\u6587\u4ef6\u5939\n\tif not os.path.exists(train_config.ckpt_save_path):\n\t\tos.mkdir(train_config.ckpt_save_path)\n\t\n\tcurrent_step = 0\n\tvalid_acc_max = 0.0\n\tvalid_loss_min = np.inf\n\tvalid_acc_model = 0\n\tvalid_loss_model = np.inf\n\tfor epoch_num in range(1, train_config.epoch_size+1):\n\t\t# train\n\t\ttrain_losses = []\n\t\ttrain_accs = []\n\t\tfor i in train_dataset.create_dict_iterator():\n\t\t\tif train_config.use_pretrained_feature_map:\n\t\t\t\ttrain_loss, train_acc = train_net(i['image_id'], i['question'], i['answer'], i['options'])\n\t\t\telse:\n\t\t\t\ttrain_loss, train_acc = train_net(i['image'], i['question'], i['answer'], i['options'])\n\t\t\ttrain_losses.append(train_loss.item(0).asnumpy().item())\n\t\t\ttrain_accs.append(train_acc.item(0).asnumpy().item())\n\t\ttrain_loss = sum(train_losses) / len(train_losses)\n\t\ttrain_acc = sum(train_accs) / len(train_accs)\n\t\tprint('epoch:', epoch_num, ' train loss =', train_loss, 'acc =', train_acc)\n\n\t\t# valid\n\t\tloss = []\n\t\tacc = []\n\t\tfor j in valid_dataset.create_dict_iterator():\n\t\t\tif train_config.use_pretrained_feature_map:\n\t\t\t\tstep_loss, step_acc = valid_net(j['image_id'], j['question'], j['answer'], j['options'])\n\t\t\telse:\n\t\t\t\tstep_loss, step_acc = valid_net(j['image'], j['question'], j['answer'], j['options'])\n\t\t\tloss.append(step_loss.item(0).asnumpy().item())\n\t\t\tacc.append(step_acc.item(0).asnumpy().item())\n\t\tvalid_loss = sum(loss) / len(loss)\n\t\tvalid_acc = sum(acc) / len(acc)\n\t\tprint('-- valid loss =', valid_loss, 'acc =', valid_acc)\n\t\t\n\t\t# save ckpt / early stop\n\t\tif valid_acc >= valid_acc_max or valid_loss < valid_loss_min:\n\t\t\tif valid_acc >= valid_acc_max and valid_loss < valid_loss_min:\n\t\t\t\tvalid_acc_model = valid_acc\n\t\t\t\tvalid_loss_model = valid_loss\n\t\t\t\tsave_checkpoint(valid_net.network, train_config.checkpoint_path)\n\t\t\t\tvalid_acc_max = np.max((valid_acc_max, valid_acc))\n\t\t\t\tvalid_loss_min = np.min((valid_loss_min, valid_loss))\n\t\t\tcurrent_step = 0\n\t\telse:\n\t\t\tcurrent_step += 1\n\t\t\tif current_step == train_config.early_stop:\n\t\t\t\tprint('early stop... min loss:', valid_loss_min, 'max acc:', valid_acc_max, end='')\n\t\t\t\tprint('; validation model loss:', valid_loss_model, 'acc:', valid_acc_model)", "metadata": {}, "execution_count": 67, "outputs": []}, {"cell_type": "code", "source": "train(train_net, valid_net, train_dataset, valid_dataset, train_config)", "metadata": {}, "execution_count": 68, "outputs": [{"ename": "RuntimeError", "evalue": "Unexpected error. Invalid data, column name: image_id can not found in schema. Please check the 'column_list'.\nLine of code : 185\nFile         : D:\\jenkins\\agent-working-dir\\workspace\\Compile_CPU_Windows_PY38\\mindspore\\mindspore\\ccsrc\\minddata\\mindrecord\\io\\shard_reader.cc\n", "output_type": "error", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)", "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10916/3217949773.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_net\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10916/3878952074.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(train_net, valid_net, train_dataset, valid_dataset, train_config)\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[0mtrain_losses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                 \u001b[0mtrain_accs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_dict_iterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_pretrained_feature_map\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                                 \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'image_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mindspore\\dataset\\engine\\validators.py\u001b[0m in \u001b[0;36mnew_method\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    969\u001b[0m             \u001b[0mcheck_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINT32_MAX\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"num_epochs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    970\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 971\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    972\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    973\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_method\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mindspore\\dataset\\engine\\datasets.py\u001b[0m in \u001b[0;36mcreate_dict_iterator\u001b[1;34m(self, num_epochs, output_numpy)\u001b[0m\n\u001b[0;32m   1476\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_noop_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1477\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mDummyIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1478\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mDictIterator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1479\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1480\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__iter__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mindspore\\dataset\\engine\\iterators.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, dataset, num_epochs, output_numpy, do_copy)\u001b[0m\n\u001b[0;32m     76\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_runtime_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     77\u001b[0m         \u001b[0mconsumer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcde\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPythonIteratorConsumer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 78\u001b[1;33m         \u001b[0mconsumer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mir_tree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     79\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_runtime_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAssignConsumer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconsumer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_runtime_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGetConsumer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;31mRuntimeError\u001b[0m: Unexpected error. Invalid data, column name: image_id can not found in schema. Please check the 'column_list'.\nLine of code : 185\nFile         : D:\\jenkins\\agent-working-dir\\workspace\\Compile_CPU_Windows_PY38\\mindspore\\mindspore\\ccsrc\\minddata\\mindrecord\\io\\shard_reader.cc\n"]}]}, {"cell_type": "code", "source": "mox.file.copy_parallel(src_url=train_config.checkpoint_path, dst_url=obs_path+train_config.checkpoint_path) ", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "markdown", "source": "## 4 \u6d4b\u8bd5\u6a21\u578b", "metadata": {}}, {"cell_type": "markdown", "source": "### 4.1 \u521b\u5efa\u6d4b\u8bd5\u6a21\u578b", "metadata": {}}, {"cell_type": "code", "source": "from mindspore import load_checkpoint\nfrom model.vqa_baseline import *\nfrom model.stack_attention import *\nfrom model.topdown_attention import *", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "# \u521b\u5efa\u7f51\u7edc\nif model_name == 'baseline':\n\tif train_config.use_op:\n\t\tnetwork = VQABasicOpAttn(train_config)\n\telse:\n\t\tnetwork = VQABasic(train_config)\nelif model_name == 'stack_attention':\n\tif train_config.use_op:\n\t\tnetwork = StackedAttentionNetOpAttn(word_dict, train_config)\n\telse:\n\t\tnetwork = StackedAttentionNet(word_dict, train_config)\nelif model_name == 'topdown_attention':\n\tif train_config.use_op:\n\t\tnetwork = TopDownAttentionNetOpAttn(word_dict, train_config)\n\telse:\n\t\tnetwork = TopDownAttentionNet(word_dict, train_config)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "load_checkpoint(train_config.checkpoint_path, net=network)\ntest_net = WithEvalCellWrapper(network, train_config)\ntest_net.set_train(False)", "metadata": {}, "execution_count": null, "outputs": [{"execution_count": 23, "output_type": "execute_result", "data": {"text/plain": "WithEvalCellWrapper<\n  (network): TopDownAttentionNet<\n    (text_net): TextFeatureCell<\n      (embeddings): Embedding<vocab_size=10233, embedding_size=200, use_one_hot=False, embedding_table=Parameter (name=text_net.embeddings.embedding_table, shape=(10233, 200), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n      >\n    (VGGnet): VGG<\n      (conv1): Conv2d<input_channels=3, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv1.weight_init, shape=(64, 3, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv2): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv2.weight_init, shape=(64, 64, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv3): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv3.weight_init, shape=(128, 64, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv4): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv4.weight_init, shape=(128, 128, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv5): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv5.weight_init, shape=(256, 128, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv6): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv6.weight_init, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv7): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv7.weight_init, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv8): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv8.weight_init, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv9): Conv2d<input_channels=256, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv9.weight_init, shape=(512, 256, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv10): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv10.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv11): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv11.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv12): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv12.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv13): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv13.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv14): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv14.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv15): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv15.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (conv16): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv16.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n      (max_pool2d): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n      (fc1): Dense<input_channels=25088, output_channels=4096, has_bias=True>\n      (fc2): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n      (relu): ReLU<>\n      (flatten): Flatten<>\n      >\n    (topdown_attn): TopDownAttentionLayer<\n      (fc_attn_nonlin): Dense<\n        input_channels=2560, output_channels=512, activation=Tanh<>\n        (activation): Tanh<>\n        >\n      (fc_attn_lin): Dense<input_channels=512, output_channels=1>\n      >\n    (fc_questions): Dense<\n      input_channels=512, output_channels=512, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (fc_images): Dense<\n      input_channels=2048, output_channels=512, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (fc_f_t): Dense<\n      input_channels=512, output_channels=300, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (fc_f_i): Dense<\n      input_channels=512, output_channels=2048, has_bias=True, activation=Tanh<>\n      (activation): Tanh<>\n      >\n    (fc_w_t): Dense<input_channels=300, output_channels=2235>\n    (fc_w_i): Dense<input_channels=2048, output_channels=2235>\n    >\n  (softmax): SoftmaxCrossEntropyWithLogits<>\n  (acc): Accuracy<>\n  >"}, "metadata": {}}]}, {"cell_type": "markdown", "source": "### 4.2 \u5f00\u59cb\u6d4b\u8bd5", "metadata": {}}, {"cell_type": "code", "source": "def test(test_net, test_dataset):\n\t# test\n\tloss = []\n\tacc = []\n\tfor i in test_dataset.create_dict_iterator():\n\t\tif train_config.use_pretrained_feature_map:\n\t\t\tstep_loss, step_acc = test_net(i['image_id'], i['question'], i['answer'], i['options'])\n\t\telse:\n\t\t\tstep_loss, step_acc = test_net(i['image'], i['question'], i['answer'], i['options'])\n\t\tloss.append(step_loss.item(0).asnumpy().item())\n\t\tacc.append(step_acc.item(0).asnumpy().item())\n\ttest_loss = sum(loss) / len(loss)\n\ttest_acc = sum(acc) / len(acc)\n\tprint('test loss =', test_loss, 'acc =', test_acc)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "test(test_net, test_dataset)", "metadata": {}, "execution_count": null, "outputs": [{"name": "stdout", "output_type": "stream", "text": "test loss = 6.822631631798814 acc = 0.20789579967689822\n"}]}, {"cell_type": "markdown", "source": "\u4ee5\u4e0b\u4e3a\u968f\u4fbf\u6d4b\u8bd5\u533a\u57df", "metadata": {}}, {"cell_type": "code", "source": "pretrained_path = './pretrained/fasterrcnnresnetv1152_ascend_v130_coco2017_official_cv_mAP41.1.ckpt'\nparams = load_checkpoint(pretrained_path)", "metadata": {}, "execution_count": null, "outputs": []}, {"cell_type": "code", "source": "params", "metadata": {}, "execution_count": null, "outputs": [{"ename": "NameError", "evalue": "name 'params' is not defined", "output_type": "error", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)", "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23076/544428641.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mparams\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[1;31mNameError\u001b[0m: name 'params' is not defined"]}]}, {"cell_type": "code", "source": "import pandas as pd\nread_file = pd.read_csv(\"f:/Desk/test2014_36/test2014_resnet101_faster_rcnn_genome_36.tsv\", sep = '\\t')", "metadata": {}, "execution_count": null, "outputs": [{"ename": "ParserError", "evalue": "Error tokenizing data. C error: out of memory", "output_type": "error", "traceback": ["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m", "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)", "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_23076/4186810917.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mread_file\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"f:/Desk/test2014_36/test2014_resnet101_faster_rcnn_genome_36.tsv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\t'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n", "\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n", "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: out of memory"]}]}, {"cell_type": "code", "source": "read_file.loc[0]", "metadata": {}, "execution_count": null, "outputs": []}]}