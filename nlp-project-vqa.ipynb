{"cells":[{"cell_type":"markdown","metadata":{},"source":["# nlp-project-vqa\n"]},{"cell_type":"code","execution_count":1,"metadata":{"trusted":true},"outputs":[],"source":["obs_path = \"s3://howie-zju/nlp/nlp_project_vqa/nlp-project-vqa/\" # howie's path\n","# obs_path = \"s3://nlp-haofeng/nlp_proje|ct_vqa/\" # hy's path\n","# obs_path = \"s3://nlp-haofeng/nlp_project_vqa/\" # zc's path\n","# obs_path = \"s3://nlp-haofeng/nlp_project_vqa/\" # ct's path"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:root:Using MoXing-v2.0.0.rc2.4b57a67b-4b57a67b\n","INFO:root:Using OBS-Python-SDK-3.20.9.1\n"]}],"source":["import moxing as mox\n","mox.file.copy_parallel(src_url=obs_path+\"mindrecord\", dst_url='./mindrecord') \n","mox.file.copy_parallel(src_url=obs_path+\"preprocess\", dst_url='./preprocess')\n","mox.file.copy_parallel(src_url=obs_path+\"utils\",      dst_url='./utils')\n","mox.file.copy_parallel(src_url=obs_path+\"model\",      dst_url='./model')\n","mox.file.copy_parallel(src_url=obs_path+\"ckpt\",       dst_url='./ckpt')\n","mox.file.copy_parallel(src_url=obs_path+\"pretrained/VGG.py\", dst_url='./pretrained/VGG.py')\n","mox.file.copy_parallel(src_url=obs_path+\"pretrained/glove.6B.200d.word2vec.txt\", dst_url='./pretrained/glove.6B.200d.word2vec.txt')\n","mox.file.copy_parallel(src_url=obs_path+\"pretrained/embeddings.py\", dst_url='./pretrained/embeddings.py')\n","mox.file.copy_parallel(src_url=obs_path+\"pretrained/__init__.py\", dst_url='./pretrained/__init__.py')\n","# mox.file.copy_parallel(src_url=obs_path+\"data\",       dst_url='./data')"]},{"cell_type":"code","execution_count":2,"metadata":{"trusted":true},"outputs":[],"source":["import mindspore\n","import numpy as np\n","import os\n","from easydict import EasyDict\n","from preprocess.preprocess import *\n","os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"  # 允许重复载入lib文件"]},{"cell_type":"markdown","metadata":{},"source":["图模式"]},{"cell_type":"code","execution_count":3,"metadata":{"trusted":true},"outputs":[],"source":["from mindspore import context\n","context.set_context(mode=context.GRAPH_MODE)"]},{"cell_type":"markdown","metadata":{},"source":["PyNative模式"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["from mindspore import context\n","context.set_context(mode=context.PYNATIVE_MODE)"]},{"cell_type":"markdown","metadata":{},"source":["Ascend 环境安装 MindSpore Hub"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["! pip install https://ms-release.obs.cn-north-4.myhuaweicloud.com/1.3.0/Hub/any/mindspore_hub-1.3.0-py3-none-any.whl --trusted-host ms-release.obs.cn-north-4.myhuaweicloud.com -i https://pypi.tuna.tsinghua.edu.cn/simple"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import mindspore_hub as mshub\n","from mindspore import context\n","\n","context.set_context(mode=context.GRAPH_MODE,\n","                    device_target=\"Ascend\",\n","                    device_id=0)\n","\n","model = \"mindspore/ascend/1.3/vgg16_cifar10\"\n","network = mshub.load(model)\n","network.set_train(False)"]},{"cell_type":"markdown","metadata":{},"source":["## 1 预处理"]},{"cell_type":"markdown","metadata":{},"source":["### 1.1 预处理配置"]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["padding = '<pad>'\n","config = EasyDict({\n","\t'train_img_path': './data/images/train/COCO_train2014_',\n","\t'train_ans_path': './data/annotations/train.json',\n","\t'train_que_path': './data/questions/train.json',\n","\t'valid_img_path': './data/images/val/COCO_val2014_',\n","\t'valid_ans_path': './data/annotations/val.json',\n","\t'valid_que_path': './data/questions/val.json',\n","\t'test_img_path': './data/images/test/COCO_val2014_',\n","\t'test_ans_path':  './data/annotations/test.json',\n","\t'test_que_path':  './data/questions/test.json',\n","\t'max_length': 25,\n","\t'dict_path': './mindrecord/dict.npy',\n","\t'idx_word_dict_path': './mindrecord/idx_word_dict.npy',\n","\t'filter_set_path': './mindrecord/',\n","\t'pretrained_path': './pretrained/',\n","\t'num_splits': 1,\n","\t'train_mindrecord_path': './mindrecord/train.mindrecord',\n","\t'valid_mindrecord_path': './mindrecord/valid.mindrecord',\n","\t'test_mindrecord_path':  './mindrecord/test.mindrecord',\n","\t'train_featurerecord_path': './featurerecord/',\n","\t'valid_featurerecord_path': './featurerecord/',\n","\t'test_featurerecord_path': './featurerecord/'\n","})"]},{"cell_type":"markdown","metadata":{},"source":["### 1.2 读取数据"]},{"cell_type":"markdown","metadata":{},"source":["注: 只取那些答案长度为1的vqa组合"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# get 3 types of input data\n","train_images, train_questions, train_answers, train_options = get_list(config.train_que_path, config.train_ans_path)\n","valid_images, valid_questions, valid_answers, valid_options = get_list(config.valid_que_path, config.valid_ans_path)\n","test_images,  test_questions,  test_answers, test_options  = get_list(config.test_que_path,  config.test_ans_path)"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["total_questions = train_questions + valid_questions + test_questions\n","total_answers   = train_answers + valid_answers + test_answers\n","total_options   = train_options + valid_options + test_options"]},{"cell_type":"markdown","metadata":{},"source":["### 1.3 构建词典"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# build word vocab\n","word_dict = dict({'<pad>': 0})\n","word_dict = add_word_into_dict(total_questions, word_dict)\n","word_dict = add_word_into_dict(total_options, word_dict)\n","\n","answer_dict = dict()\n","answer_dict = add_answer_into_dict(total_answers, answer_dict)"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["# build revert dict\n","idx_word_dict = dict()\n","for item in word_dict.items():\n","\tidx_word_dict[item[1]] = item[0]"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"data":{"text/plain":["8193"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["len(answer_dict)"]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[],"source":["# save dict\n","np.save(config.dict_path, word_dict)\n","np.save(config.idx_word_dict_path, idx_word_dict)"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["mox.file.copy_parallel(src_url=\"./mindrecord/dict.npy\", dst_url=obs_path+\"mindrecord/dict.npy\")\n","mox.file.copy_parallel(src_url=\"./mindrecord/idx_word_dict.npy\", dst_url=obs_path+\"mindrecord/idx_word_dict.npy\") "]},{"cell_type":"markdown","metadata":{},"source":["### 1.4 向量化 & 补齐长度"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[],"source":["# word -> vector & padding\n","train_questions_vec = get_vec_and_pad(train_questions, word_dict, config.max_length)\n","valid_questions_vec = get_vec_and_pad(valid_questions, word_dict, config.max_length)\n","test_questions_vec = get_vec_and_pad(test_questions, word_dict, config.max_length)\n","\n","train_options_vec = get_option_vec_and_pad(train_options, word_dict, 1)\n","valid_options_vec = get_option_vec_and_pad(valid_options, word_dict, 1)\n","test_options_vec = get_option_vec_and_pad(test_options, word_dict, 1)\n","\n","train_answers_vec, _, _, _ = get_answer_to_idx(train_answers, answer_dict)\n","valid_answers_vec, _, _, _ = get_answer_to_idx(valid_answers, answer_dict)\n","test_answers_vec, _, _, _ = get_answer_to_idx(test_answers, answer_dict)\n","_, bool_set, num_set, other_set = get_answer_to_idx(total_answers, answer_dict)"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# 保存集合\n","np.save(config.filter_set_path+'bool.npy', bool_set)\n","np.save(config.filter_set_path+'num.npy', num_set)\n","np.save(config.filter_set_path+'other.npy', other_set)"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# 删除 data 文件夹下的文件，以节省空间\n","import os\n","\n","for root,dirs,files in os.walk(\"./data\"):\n","    for file in files:\n","        os.remove(root+\"/\"+file)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# 在服务器上创建 featurerecord 文件夹\n","! mkdir featurerecord"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["train_combine_dict = dict()\n","for i, q, a, o in zip(train_images, train_questions_vec, train_answers_vec, train_options_vec):\n","    j=0\n","    while train_combine_dict.__contains__((i, j)):\n","        j += 1\n","    train_combine_dict[(i, j)] = (q, a, o)\n","    \n","valid_combine_dict = dict()\n","for i, q, a, o in zip(valid_images, valid_questions_vec, valid_answers_vec, valid_options_vec):\n","    j=0\n","    while valid_combine_dict.__contains__((i, j)):\n","        j += 1\n","    valid_combine_dict[(i, j)] = (q, a, o)\n","\n","test_combine_dict = dict()\n","for i, q, a, o in zip(test_images, test_questions_vec, test_answers_vec, test_options_vec):\n","    j=0\n","    while test_combine_dict.__contains__((i, j)):\n","        j += 1\n","    test_combine_dict[(i, j)] = (q, a, o)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["train_data_dict = dict()\n","valid_data_dict = dict()\n","test_data_dict = dict()\n","\n","# id in range(1, 14)\n","id = 1\n","# mox.file.copy_parallel(src_url=obs_path+\"pretrained/feature_map\" + str(id) + \".npy\", dst_url='./pretrained/feature_map' + str(id) + '.npy')\n","feature_map_set = np.load('./pretrained/feature_map' + str(id) + '.npy', allow_pickle=True).item()\n","\n","for key, value in feature_map_set.items():\n","    j = 0\n","    while train_combine_dict.__contains__((key, j)):\n","        train_data_dict[(key, j)] = (value.view(np.float32), train_combine_dict[(key, j)])\n","        j += 1\n","    j = 0\n","    while valid_combine_dict.__contains__((key, j)):\n","        valid_data_dict[(key, j)] = (value.view(np.float32), valid_combine_dict[(key, j)])\n","        j += 1\n","    j = 0\n","    while test_combine_dict.__contains__((key, j)):\n","        test_data_dict[(key, j)] = (value.view(np.float32), test_combine_dict[(key, j)])\n","        j += 1\n","\n","# try:\n","# \tos.remove('./pretrained/feature_map' + str(id) + '.npy')\n","# \tprint(\"-- delete file successfully!\")\n","# except(FileNotFoundError):\n","# \tprint(\"-- file not exists!\")"]},{"cell_type":"code","execution_count":55,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train12\n"]}],"source":["generate_featurerecord(\"./featurerecord/train\" + str(id) + \".mindrecord\", 1, train_data_dict)"]},{"cell_type":"code","execution_count":56,"metadata":{},"outputs":[],"source":["mox.file.copy_parallel(src_url=\"./featurerecord/train\" + str(id) + \".mindrecord\",    dst_url=obs_path+\"featurerecord/train\" + str(id) + \".mindrecord\") \n","mox.file.copy_parallel(src_url=\"./featurerecord/train\" + str(id) + \".mindrecord.db\", dst_url=obs_path+\"featurerecord/train\" + str(id) + \".mindrecord.db\") "]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["valid1\n"]},{"ename":"RuntimeError","evalue":"Unexpected error. Invalid file, mindrecord files already exist. Please check file path: f:\\Desk\\nlp_VQA\\featurerecord\\valid1.mindrecord.\nIf you do not want to keep the files, set the 'overwrite' parameter to True and try again.\nLine of code : 116\nFile         : D:\\jenkins\\agent-working-dir\\workspace\\Compile_CPU_Windows_PY38\\mindspore\\mindspore\\ccsrc\\minddata\\mindrecord\\io\\shard_writer.cc\n","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12460/1915201200.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgenerate_featurerecord\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./featurerecord/valid\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".mindrecord\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_data_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[1;32mf:\\Desk\\nlp_VQA\\preprocess\\preprocess.py\u001b[0m in \u001b[0;36mgenerate_featurerecord\u001b[1;34m(featurerecord_path, num_splits, data_dict)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \t\t\t}\n\u001b[0;32m    221\u001b[0m                 \u001b[0mdata_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_raw_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mindspore\\mindrecord\\filewriter.py\u001b[0m in \u001b[0;36mwrite_raw_data\u001b[1;34m(self, raw_data, parallel_writer)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \"\"\"\n\u001b[0;32m    314\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 315\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_overwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    316\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_shard_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_shard_header\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_header\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;32mc:\\Users\\lenovo\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\mindspore\\mindrecord\\shardwriter.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, paths, override)\u001b[0m\n\u001b[0;32m     50\u001b[0m             \u001b[0mMRMOpenError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mMindRecord\u001b[0m \u001b[0mFile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \"\"\"\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_writer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpaths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mms\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMSRStatus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSUCCESS\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcritical\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Failed to open paths\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n","\u001b[1;31mRuntimeError\u001b[0m: Unexpected error. Invalid file, mindrecord files already exist. Please check file path: f:\\Desk\\nlp_VQA\\featurerecord\\valid1.mindrecord.\nIf you do not want to keep the files, set the 'overwrite' parameter to True and try again.\nLine of code : 116\nFile         : D:\\jenkins\\agent-working-dir\\workspace\\Compile_CPU_Windows_PY38\\mindspore\\mindspore\\ccsrc\\minddata\\mindrecord\\io\\shard_writer.cc\n"]}],"source":["generate_featurerecord(\"./featurerecord/valid\" + str(id) + \".mindrecord\", 1, valid_data_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mox.file.copy_parallel(src_url=\"./featurerecord/valid\" + str(id) + \".mindrecord\",    dst_url=obs_path+\"featurerecord/valid\" + str(id) + \".mindrecord\") \n","mox.file.copy_parallel(src_url=\"./featurecord/valid\" + str(id) + \".mindrecord.db\", dst_url=obs_path+\"featurerecord/valid\" + str(id) + \".mindrecord.db\") "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["generate_featurerecord(\"./featurerecord/test\" + str(id) + \".mindrecord\", 1, test_data_dict)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mox.file.copy_parallel(src_url=\"./featurerecord/test\" + str(id) + \".mindrecord\",    dst_url=obs_path+\"featurerecord/test\" + str(id) + \".mindrecord\") \n","mox.file.copy_parallel(src_url=\"./featurerecord/test\" + str(id) + \".mindrecord.db\", dst_url=obs_path+\"featurerecord/test\" + str(id) + \".mindrecord.db\") "]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[{"data":{"text/plain":["43740"]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["cnt = 0\n","for answer in total_answers:\n","    # print(answer)\n","    if answer_dict[answer] in other_set:\n","        cnt += 1\n","cnt"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"data":{"text/plain":["87245"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["len(total_answers)"]},{"cell_type":"markdown","metadata":{},"source":["### 1.5 取频率较高的那些词得到答案词集"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["total_answers_vec = train_answers_vec + valid_answers_vec + test_answers_vec\n","least_2_set = get_filtered_answer_set(total_answers_vec, 2) # 2958\n","least_6_set = get_filtered_answer_set(total_answers_vec, 6) # 999"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"data":{"text/plain":["2958"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["len(least_2_set)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"data":{"text/plain":["999"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["len(least_6_set)"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["# 保存集合\n","np.save(config.filter_set_path+'min2.npy', least_2_set)\n","np.save(config.filter_set_path+'min6.npy', least_6_set)"]},{"cell_type":"markdown","metadata":{},"source":["### 1.6 生成MindRecord"]},{"cell_type":"markdown","metadata":{},"source":["train"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["train\n"]}],"source":["generate_mindrecord(config.train_mindrecord_path, config.train_img_path, config.num_splits, train_images, train_questions_vec, train_answers_vec, train_options_vec)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["mox.file.copy_parallel(src_url=\"./mindrecord/train.mindrecord\",    dst_url=obs_path+\"mindrecord/train.mindrecord\") \n","mox.file.copy_parallel(src_url=\"./mindrecord/train.mindrecord.db\", dst_url=obs_path+\"mindrecord/train.mindrecord.db\") "]},{"cell_type":"markdown","metadata":{},"source":["valid"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["valid\n"]}],"source":["generate_mindrecord(config.valid_mindrecord_path, config.valid_img_path, config.num_splits, valid_images, valid_questions_vec, valid_answers_vec, valid_options_vec)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["bool.npy\t   min2.npy  num.npy\t       train.mindrecord.db\n","dict.npy\t   min5.npy  other.npy\t       valid.mindrecord\n","idx_word_dict.npy  min6.npy  train.mindrecord  valid.mindrecord.db\n"]}],"source":["! ls mindrecord"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["mox.file.copy_parallel(src_url=\"./mindrecord/valid.mindrecord\",    dst_url=obs_path+\"mindrecord/valid.mindrecord\") \n","mox.file.copy_parallel(src_url=\"./mindrecord/valid.mindrecord.db\", dst_url=obs_path+\"mindrecord/valid.mindrecord.db\") "]},{"cell_type":"markdown","metadata":{},"source":["test"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test\n"]}],"source":["generate_mindrecord(config.test_mindrecord_path, config.test_img_path, config.num_splits, test_images, test_questions_vec, test_answers_vec, test_options_vec)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["mox.file.copy_parallel(src_url=\"./mindrecord/test.mindrecord\",    dst_url=obs_path+\"mindrecord/test.mindrecord\") \n","mox.file.copy_parallel(src_url=\"./mindrecord/test.mindrecord.db\", dst_url=obs_path+\"mindrecord/test.mindrecord.db\") "]},{"cell_type":"markdown","metadata":{},"source":["## 2 加载数据"]},{"cell_type":"markdown","metadata":{},"source":["### 2.1 加载词典、集合"]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["# load dict\n","word_dict = np.load(config.dict_path, allow_pickle=True).item()\n","idx_word_dict = np.load(config.idx_word_dict_path, allow_pickle=True).item()"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[],"source":["# load filter set\n","least_2_set = np.load(config.filter_set_path+'min2.npy', allow_pickle=True).item()\n","least_6_set = np.load(config.filter_set_path+'min6.npy', allow_pickle=True).item()\n","bool_set = np.load(config.filter_set_path+'bool.npy', allow_pickle=True).item()\n","num_set = np.load(config.filter_set_path+'num.npy', allow_pickle=True).item()\n","other_set = np.load(config.filter_set_path+'other.npy', allow_pickle=True).item()"]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[],"source":["# set -> dict\n","least_2_dict = set_to_dict(least_2_set)\n","least_6_dict = set_to_dict(least_6_set)\n","\n","bool_dict = set_to_dict(bool_set)\n","num_dict = set_to_dict(num_set)\n","other_dict = set_to_dict(other_set)"]},{"cell_type":"markdown","metadata":{},"source":["### 2.2 训练配置"]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[],"source":["# model_name = 'baseline'\n","# model_name = 'stack_attention'\n","model_name = 'topdown_attention'"]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[],"source":["# batch_size = 32 # baseline\n","# batch_size = 100 # stacked attention\n","batch_size = 128 # top-down attention"]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in indexes: http://repo.myhuaweicloud.com/repository/pypi/simple\n","Collecting gensim\n","  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/9f/10/0a737b7f935a14ac49d12187530952805978e1be506212b7c66d15962e27/gensim-4.2.0-cp37-cp37m-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (24.0 MB)\n","\u001b[K     |████████████████████████████████| 24.0 MB 46.7 MB/s eta 0:00:01     |███████████████████████████▊    | 20.8 MB 46.7 MB/s eta 0:00:01\n","\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from gensim) (1.5.4)\n","Requirement already satisfied: numpy>=1.17.0 in /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages (from gensim) (1.17.5)\n","Collecting smart-open>=1.8.1\n","  Downloading http://repo.myhuaweicloud.com/repository/pypi/packages/09/db/fab79b619923e26cecc5fb460c80f71f99666fe19182d5bb600ec4d6ff10/smart_open-6.0.0-py3-none-any.whl (58 kB)\n","\u001b[K     |████████████████████████████████| 58 kB 45.9 MB/s eta 0:00:01\n","\u001b[?25hInstalling collected packages: smart-open, gensim\n","Successfully installed gensim-4.2.0 smart-open-6.0.0\n"]}],"source":["! pip install gensim"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[],"source":["train_config = EasyDict({\n","\t'model': model_name,\n","\t'vocab_size': 52083,\n","\t'output_size': 999 if model_name == 'baseline' or model_name == 'stack_attention' else 2958,\n","\t'batch_size': batch_size,\n","\t'epoch_size': 3,\n","\t'max_length': 14,\n","\t'use_op': False,\n","\t'use_pretrained_feature_map': True,\n","\t'hidden_size': 1024,\n","\t'lr': 1e-4,\n","\t'momentum': 0.9,\n","\t'weight_decay': 3e-5,\n","\t'early_stop': 100,\n","\t'ckpt_save_path': './ckpt',\n","\t'checkpoint_path': './ckpt/'+model_name+'.ckpt',\n","\t'pretrained_path': './pretrained/vgg19_ascend_v130_imagenet2012_research_cv_top1acc74_top5acc91.97.ckpt',\n","\t'embedding_table_path': './pretrained/embedding_table_glove_200d.txt',\n","\t'glove_vector_path': './pretrained/glove.6B.200d.txt',\n","\t'glove_word2vec_path': './pretrained/glove.6B.200d.word2vec.txt',\n","\t'train_featurerecord_path': './featurerecord/',\n","\t'valid_featurerecord_path': './featurerecord/',\n","\t'test_featurerecord_path': './featurerecord/'\n","})"]},{"cell_type":"markdown","metadata":{},"source":["### 2.3 生成数据集"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[],"source":["# platform = 'Local'\n","# platform = 'Colob'\n","platform = 'Ascend'"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["4\n"]}],"source":["# frequency filter dict\n","filter_dict = least_6_dict if model_name == 'baseline' or model_name == 'stack_attention' else least_2_dict\n","# image size\n","image_width = 224 if model_name == 'baseline' else 448\n","image_height = 224 if model_name == 'baseline' else 448\n","# parallel workers\n","num_parallel_workers = 4 if platform == 'Ascend' or platform == 'Local' else 2\n","print(num_parallel_workers)\n","# create dataset\n","train_dataset = generate_dataset(config.train_mindrecord_path, train_config.batch_size, 1, train_config.max_length, \n","                                 filter_dict, image_height, image_width, num_parallel_workers)\n","valid_dataset = generate_dataset(config.valid_mindrecord_path, train_config.batch_size, 1, train_config.max_length, \n","                                 filter_dict, image_height, image_width, num_parallel_workers)\n","test_dataset  = generate_dataset(config.test_mindrecord_path , train_config.batch_size, 1, train_config.max_length, \n","                                 filter_dict, image_height, image_width, num_parallel_workers)"]},{"cell_type":"markdown","metadata":{},"source":["## 3 训练模型"]},{"cell_type":"markdown","metadata":{},"source":["### 3.1 创建模型"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[],"source":["import mindspore.nn as nn\n","import mindspore.ops.operations as P\n","from utils.metric_utils import *\n","from utils.wrapper_utils import *\n","from utils.callback_utils import *"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[],"source":["class Network(nn.Cell):\n","\tdef __init__(self, train_config):\n","\t\tsuper(Network, self).__init__()\n","\t\tself.reshape = P.Reshape()\n","\t\tself.embedding = nn.Embedding(train_config.vocab_size, train_config.hidden_size)\n","\t\tself.out = nn.Dense(train_config.hidden_size*train_config.max_length, train_config.output_size)\n","\tdef construct(self, images, questions):\n","\t\tx = self.embedding(questions)\n","\t\tx = x.reshape(x.shape[0], -1)\n","\t\tx = self.out(x)\n","\t\treturn x"]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["from model.vqa_baseline import *\n","from model.stack_attention import *\n","from model.topdown_attention import *"]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["INFO:gensim.models.keyedvectors:loading projection weights from ./pretrained/glove.6B.200d.word2vec.txt\n","INFO:gensim.utils:KeyedVectors lifecycle event {'msg': 'loaded (400000, 200) matrix of type float32 from ./pretrained/glove.6B.200d.word2vec.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2022-06-28T07:32:20.534567', 'gensim': '4.2.0', 'python': '3.7.6 | packaged by conda-forge | (default, Jun  1 2020, 18:15:32) \\n[GCC 7.5.0]', 'platform': 'Linux-4.19.36-vhulk1907.1.0.h619.eulerosv2r8.aarch64-aarch64-with-centos-2.0-SP8', 'event': 'load_word2vec_format'}\n"]}],"source":["# 创建网络\n","if model_name == 'baseline':\n","\tif train_config.use_op:\n","\t\tnetwork = VQABasicOpAttn(train_config)\n","\telse:\n","\t\tnetwork = VQABasic(train_config)\n","elif model_name == 'stack_attention':\n","\tif train_config.use_op:\n","\t\tnetwork = StackedAttentionNetOpAttn(word_dict, train_config)\n","\telse:\n","\t\tnetwork = StackedAttentionNet(word_dict, train_config)\n","elif model_name == 'topdown_attention':\n","\tif train_config.use_op and train_config.use_pretrained_feature_map:\n","\t\tnetwork = TopDownAttentionNetOpAttn(word_dict, train_config)\n","\telif train_config.use_op:\n","\t\tnetwork = TopDownAttentionNetOpAttn(word_dict, train_config)\n","\telif train_config.use_pretrained_feature_map:\n","\t\tnetwork = TopDownAttentionNetFeature(word_dict, train_config)\n","\telse:\n","\t\tnetwork = TopDownAttentionNet(word_dict, train_config)"]},{"cell_type":"code","execution_count":46,"metadata":{},"outputs":[],"source":["# questions = Tensor(np.zeros((32, 14), dtype=np.int32))\n","# images = Tensor(np.zeros((32, 448, 448, 3), dtype=np.int8))\n","# options = Tensor(np.zeros((32, 10), dtype=np.int32))\n","# output = network(images, questions, options)\n","# print(output)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["WithEvalCellWrapper<\n","  (network): TopDownAttentionNetFeature<\n","    (text_net): TextFeatureCell<\n","      (embeddings): Embedding<vocab_size=52083, embedding_size=200, use_one_hot=False, embedding_table=Parameter (name=text_net.embeddings.embedding_table, shape=(52083, 200), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n","      >\n","    (fc_feature): Dense<\n","      input_channels=8192, output_channels=2048, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (topdown_attn): TopDownAttentionLayer<\n","      (fc_attn_nonlin): Dense<\n","        input_channels=2560, output_channels=512, activation=Tanh<>\n","        (activation): Tanh<>\n","        >\n","      (fc_attn_lin): Dense<input_channels=512, output_channels=1>\n","      >\n","    (fc_questions): Dense<\n","      input_channels=512, output_channels=512, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (fc_images): Dense<\n","      input_channels=2048, output_channels=512, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (fc_f_t): Dense<\n","      input_channels=512, output_channels=300, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (fc_f_i): Dense<\n","      input_channels=512, output_channels=2048, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (fc_w_t): Dense<input_channels=300, output_channels=2958>\n","    (fc_w_i): Dense<input_channels=2048, output_channels=2958>\n","    >\n","  (softmax): SoftmaxCrossEntropyWithLogits<>\n","  (acc): Accuracy<>\n","  >"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["# 创建训练、测试网络\n","loss_fn = nn.SoftmaxCrossEntropyWithLogits(sparse=True)\n","# train network\n","train_net = TrainNetworkWrapper(network, loss_fn, train_config)\n","train_net.set_train(True)\n","# valid network\n","valid_net = WithEvalCellWrapper(network, train_config)\n","valid_net.set_train(False)"]},{"cell_type":"markdown","metadata":{},"source":["### 3.2 开始训练"]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[],"source":["def train(train_net, valid_net, train_dataset, valid_dataset, train_config):\n","\t# 创建文件夹\n","\tif not os.path.exists(train_config.ckpt_save_path):\n","\t\tos.mkdir(train_config.ckpt_save_path)\n","\t\n","\tcurrent_step = 0\n","\tvalid_acc_max = 0.0\n","\tvalid_loss_min = np.inf\n","\tvalid_acc_model = 0\n","\tvalid_loss_model = np.inf\n","\tfor epoch_num in range(1, train_config.epoch_size+1):\n","\t\t# train\n","\t\ttrain_losses = []\n","\t\ttrain_accs = []\n","\t\tfor i in train_dataset.create_dict_iterator():\n","\t\t\ttrain_loss, train_acc = train_net(i['image'], i['question'], i['answer'], i['options'])\n","\t\t\ttrain_losses.append(train_loss.item(0).asnumpy().item())\n","\t\t\ttrain_accs.append(train_acc.item(0).asnumpy().item())\n","\t\ttrain_loss = sum(train_losses) / len(train_losses)\n","\t\ttrain_acc = sum(train_accs) / len(train_accs)\n","\t\tprint('epoch:', epoch_num, ' train loss =', train_loss, 'acc =', train_acc)\n","\n","\t\t# valid\n","\t\tloss = []\n","\t\tacc = []\n","\t\tfor j in valid_dataset.create_dict_iterator():\n","\t\t\tstep_loss, step_acc = valid_net(j['image'], j['question'], j['answer'], j['options'])\n","\t\t\tloss.append(step_loss.item(0).asnumpy().item())\n","\t\t\tacc.append(step_acc.item(0).asnumpy().item())\n","\t\tvalid_loss = sum(loss) / len(loss)\n","\t\tvalid_acc = sum(acc) / len(acc)\n","\t\tprint('-- valid loss =', valid_loss, 'acc =', valid_acc)\n","\t\t\n","\t\t# save ckpt / early stop\n","\t\tif valid_acc >= valid_acc_max or valid_loss < valid_loss_min:\n","\t\t\tif valid_acc >= valid_acc_max and valid_loss < valid_loss_min:\n","\t\t\t\tvalid_acc_model = valid_acc\n","\t\t\t\tvalid_loss_model = valid_loss\n","\t\t\t\tsave_checkpoint(valid_net.network, train_config.checkpoint_path)\n","\t\t\t\tvalid_acc_max = np.max((valid_acc_max, valid_acc))\n","\t\t\t\tvalid_loss_min = np.min((valid_loss_min, valid_loss))\n","\t\t\tcurrent_step = 0\n","\t\telse:\n","\t\t\tcurrent_step += 1\n","\t\t\tif current_step == train_config.early_stop:\n","\t\t\t\tprint('early stop... min loss:', valid_loss_min, 'max acc:', valid_acc_max, end='')\n","\t\t\t\tprint('; validation model loss:', valid_loss_model, 'acc:', valid_acc_model)"]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[],"source":["import os\n","\n","def train_feature_map(train_net, valid_net, train_config, filter_dict):\n","\t# 创建文件夹\n","\tif not os.path.exists(train_config.ckpt_save_path):\n","\t\tos.mkdir(train_config.ckpt_save_path)\n","\t\n","\tcurrent_step = 0\n","\tvalid_acc_max = 0.0\n","\tvalid_loss_min = np.inf\n","\tvalid_acc_model = 0\n","\tvalid_loss_model = np.inf\n","\tfor epoch_num in range(1, train_config.epoch_size+1):\n","\t\t# train\n","\t\ttrain_losses = []\n","\t\ttrain_accs = []\n","\t\tfor id in range(1, 14):\n","\t\t\tmox.file.copy_parallel(src_url= obs_path+train_config.train_featurerecord_path + \"train\" + str(id) + \".mindrecord\",    dst_url=train_config.train_featurerecord_path + \"train\" + str(id) + \".mindrecord\") \n","\t\t\tmox.file.copy_parallel(src_url= obs_path+train_config.train_featurerecord_path + \"train\" + str(id) + \".mindrecord.db\",    dst_url=train_config.train_featurerecord_path + \"train\" + str(id) + \".mindrecord.db\") \n","\t\t\ttrain_dataset = generate_feature_map_dataset(train_config.train_featurerecord_path + 'train'+str(id)+'.mindrecord', train_config.batch_size, 1, train_config.max_length, filter_dict)\n","\t\t\tfor i in train_dataset.create_dict_iterator():\n","\t\t\t\ttrain_loss, train_acc = train_net(i['image'], i['question'], i['answer'], i['options'])\n","\t\t\t\ttrain_losses.append(train_loss.item(0).asnumpy().item())\n","\t\t\t\ttrain_accs.append(train_acc.item(0).asnumpy().item())\n","\t\t\t# delete file\n","\t\t\ttry:\n","\t\t\t\tos.remove(train_config.train_featurerecord_path + \"train\" + str(id) + \".mindrecord\")\n","\t\t\t\tos.remove(train_config.train_featurerecord_path + \"train\" + str(id) + \".mindrecord.db\")\n","\t\t\t\tprint(\"-- delete file successfully!\")\n","\t\t\texcept(FileNotFoundError):\n","\t\t\t\tprint(\"-- file not exists!\")\n","    \n","\t\ttrain_loss = sum(train_losses) / len(train_losses)\n","\t\ttrain_acc = sum(train_accs) / len(train_accs)\n","\t\tprint('epoch:', epoch_num, ' train loss =', train_loss, 'acc =', train_acc)\n","\n","\t\t# valid\n","\t\tloss = []\n","\t\tacc = []\n","\t\tfor id in range(1, 2):\n","\t\t\tmox.file.copy_parallel(src_url= obs_path+train_config.train_featurerecord_path + \"valid\" + str(id) + \".mindrecord\",    dst_url=train_config.train_featurerecord_path + \"valid\" + str(id) + \".mindrecord\") \n","\t\t\tmox.file.copy_parallel(src_url= obs_path+train_config.train_featurerecord_path + \"valid\" + str(id) + \".mindrecord.db\",    dst_url=train_config.train_featurerecord_path + \"valid\" + str(id) + \".mindrecord.db\") \n","\t\t\tvalid_dataset = generate_feature_map_dataset(train_config.train_featurerecord_path + 'valid'+str(id)+'.mindrecord', train_config.batch_size, 1, train_config.max_length, filter_dict)\n","\t\t\tfor j in valid_dataset.create_dict_iterator():\n","\t\t\t\tstep_loss, step_acc = valid_net(j['image'], j['question'], j['answer'], j['options'])\n","\t\t\t\tloss.append(step_loss.item(0).asnumpy().item())\n","\t\t\t\tacc.append(step_acc.item(0).asnumpy().item())\n","\t\t\t# delete file\n","\t\t\ttry:\n","\t\t\t\tos.remove(train_config.train_featurerecord_path + \"valid\" + str(id) + \".mindrecord\")\n","\t\t\t\tos.remove(train_config.train_featurerecord_path + \"valid\" + str(id) + \".mindrecord.db\")\n","\t\t\t\tprint(\"-- delete file successfully!\")\n","\t\t\texcept(FileNotFoundError):\n","\t\t\t\tprint(\"-- file not exists!\")\n","    \n","\t\tvalid_loss = sum(loss) / len(loss)\n","\t\tvalid_acc = sum(acc) / len(acc)\n","\t\tprint('-- valid loss =', valid_loss, 'acc =', valid_acc)\n","\t\t\n","\t\t# save ckpt / early stop\n","\t\tif valid_acc >= valid_acc_max or valid_loss < valid_loss_min:\n","\t\t\tif valid_acc >= valid_acc_max and valid_loss < valid_loss_min:\n","\t\t\t\tvalid_acc_model = valid_acc\n","\t\t\t\tvalid_loss_model = valid_loss\n","\t\t\t\tsave_checkpoint(valid_net.network, train_config.checkpoint_path)\n","\t\t\t\tvalid_acc_max = np.max((valid_acc_max, valid_acc))\n","\t\t\t\tvalid_loss_min = np.min((valid_loss_min, valid_loss))\n","\t\t\tcurrent_step = 0\n","\t\telse:\n","\t\t\tcurrent_step += 1\n","\t\t\tif current_step == train_config.early_stop:\n","\t\t\t\tprint('early stop... min loss:', valid_loss_min, 'max acc:', valid_acc_max, end='')\n","\t\t\t\tprint('; validation model loss:', valid_loss_model, 'acc:', valid_acc_model)"]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"ename":"TypeError","evalue":"mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:77 DoJump] Function construct.1, The number of parameters of this function is 4, but the number of provided arguments is 3. NodeInfo: In file /home/ma-user/work/utils/wrapper_utils.py(13)\n\tdef construct(self, images, questions, answers, options):\r\n ^\n\nThe function call stack (See file 'analyze_fail_0.dat' for more details):\n# 0 In file /home/ma-user/work/utils/wrapper_utils.py(51)\n\t\tif self.use_op:\r\n# 1 In file /home/ma-user/work/utils/wrapper_utils.py(56)\n\t\t\tloss = self._backbone(images, questions, answers)\r\n          ^\n# 2 In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)\n        if self.freeze:\n# 3 In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)\n            if self.use_grad_accumulation:\n# 4 In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(390)\n            loss = self.network(*inputs)\n                   ^\n","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-dec497fb802b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_pretrained_feature_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain_feature_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-df25de51f3bc>\u001b[0m in \u001b[0;36mtrain_feature_map\u001b[0;34m(train_net, valid_net, train_config, filter_dict)\u001b[0m\n\u001b[1;32m     20\u001b[0m                         \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_feature_map_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_featurerecord_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'train'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'.mindrecord'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_dict_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m                                 \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'answer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'options'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                                 \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                                 \u001b[0mtrain_accs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_acc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    384\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_hook\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The graph mode does not support hook function.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile_and_run\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \"\"\"\n\u001b[1;32m    643\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_compile_and_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0mnew_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/cell.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, *inputs)\u001b[0m\n\u001b[1;32m    629\u001b[0m             \u001b[0minputs\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mInputs\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCell\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m         \"\"\"\n\u001b[0;32m--> 631\u001b[0;31m         \u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauto_parallel_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_auto_parallel_mode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_and_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m~/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/common/api.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, obj, phase, do_convert, auto_parallel_mode, *args)\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0menable_ge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"enable_ge\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m         \u001b[0muse_vm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menable_ge\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0menable_debug_runtime\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPYNATIVE_MODE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_vm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqueue_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile_cache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphase\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: mindspore/ccsrc/pipeline/jit/static_analysis/stack_frame.cc:77 DoJump] Function construct.1, The number of parameters of this function is 4, but the number of provided arguments is 3. NodeInfo: In file /home/ma-user/work/utils/wrapper_utils.py(13)\n\tdef construct(self, images, questions, answers, options):\r\n ^\n\nThe function call stack (See file 'analyze_fail_0.dat' for more details):\n# 0 In file /home/ma-user/work/utils/wrapper_utils.py(51)\n\t\tif self.use_op:\r\n# 1 In file /home/ma-user/work/utils/wrapper_utils.py(56)\n\t\t\tloss = self._backbone(images, questions, answers)\r\n          ^\n# 2 In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(377)\n        if self.freeze:\n# 3 In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(394)\n            if self.use_grad_accumulation:\n# 4 In file /home/ma-user/miniconda3/envs/MindSpore-python3.7-aarch64/lib/python3.7/site-packages/mindspore/nn/wrap/cell_wrapper.py(390)\n            loss = self.network(*inputs)\n                   ^\n"]}],"source":["if train_config.use_pretrained_feature_map:\n","    train_feature_map(train_net, valid_net, train_config, filter_dict)\n","else:\n","    train(train_net, valid_net, train_dataset, valid_dataset, train_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["mox.file.copy_parallel(src_url=train_config.checkpoint_path, dst_url=obs_path+train_config.checkpoint_path) "]},{"cell_type":"markdown","metadata":{},"source":["## 4 测试模型"]},{"cell_type":"markdown","metadata":{},"source":["### 4.1 创建测试模型"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from mindspore import load_checkpoint\n","from model.vqa_baseline import *\n","from model.stack_attention import *\n","from model.topdown_attention import *"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 创建网络\n","if model_name == 'baseline':\n","\tif train_config.use_op:\n","\t\tnetwork = VQABasicOpAttn(train_config)\n","\telse:\n","\t\tnetwork = VQABasic(train_config)\n","elif model_name == 'stack_attention':\n","\tif train_config.use_op:\n","\t\tnetwork = StackedAttentionNetOpAttn(word_dict, train_config)\n","\telse:\n","\t\tnetwork = StackedAttentionNet(word_dict, train_config)\n","elif model_name == 'topdown_attention':\n","\tif train_config.use_op and train_config.use_pretrained_feature_map:\n","\t\tnetwork = TopDownAttentionNetOpAttn(word_dict, train_config)\n","\telif train_config.use_op:\n","\t\tnetwork = TopDownAttentionNetOpAttn(word_dict, train_config)\n","\telif train_config.use_pretrained_feature_map:\n","\t\tnetwork = TopDownAttentionNetFeature(word_dict, train_config)\n","\telse:\n","\t\tnetwork = TopDownAttentionNet(word_dict, train_config)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"data":{"text/plain":["WithEvalCellWrapper<\n","  (network): TopDownAttentionNet<\n","    (text_net): TextFeatureCell<\n","      (embeddings): Embedding<vocab_size=10233, embedding_size=200, use_one_hot=False, embedding_table=Parameter (name=text_net.embeddings.embedding_table, shape=(10233, 200), dtype=Float32, requires_grad=True), dtype=Float32, padding_idx=None>\n","      >\n","    (VGGnet): VGG<\n","      (conv1): Conv2d<input_channels=3, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv1.weight_init, shape=(64, 3, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv2): Conv2d<input_channels=64, output_channels=64, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv2.weight_init, shape=(64, 64, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv3): Conv2d<input_channels=64, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv3.weight_init, shape=(128, 64, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv4): Conv2d<input_channels=128, output_channels=128, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv4.weight_init, shape=(128, 128, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv5): Conv2d<input_channels=128, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv5.weight_init, shape=(256, 128, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv6): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv6.weight_init, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv7): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv7.weight_init, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv8): Conv2d<input_channels=256, output_channels=256, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv8.weight_init, shape=(256, 256, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv9): Conv2d<input_channels=256, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv9.weight_init, shape=(512, 256, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv10): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv10.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv11): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv11.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv12): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv12.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv13): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv13.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv14): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv14.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv15): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv15.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (conv16): Conv2d<input_channels=512, output_channels=512, kernel_size=(3, 3), stride=(1, 1), pad_mode=same, padding=0, dilation=(1, 1), group=1, has_bias=False, weight_init=Parameter (name=VGGnet.conv16.weight_init, shape=(512, 512, 3, 3), dtype=Float32, requires_grad=False), bias_init=zeros, format=NCHW>\n","      (max_pool2d): MaxPool2d<kernel_size=2, stride=2, pad_mode=VALID>\n","      (fc1): Dense<input_channels=25088, output_channels=4096, has_bias=True>\n","      (fc2): Dense<input_channels=4096, output_channels=4096, has_bias=True>\n","      (relu): ReLU<>\n","      (flatten): Flatten<>\n","      >\n","    (topdown_attn): TopDownAttentionLayer<\n","      (fc_attn_nonlin): Dense<\n","        input_channels=2560, output_channels=512, activation=Tanh<>\n","        (activation): Tanh<>\n","        >\n","      (fc_attn_lin): Dense<input_channels=512, output_channels=1>\n","      >\n","    (fc_questions): Dense<\n","      input_channels=512, output_channels=512, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (fc_images): Dense<\n","      input_channels=2048, output_channels=512, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (fc_f_t): Dense<\n","      input_channels=512, output_channels=300, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (fc_f_i): Dense<\n","      input_channels=512, output_channels=2048, has_bias=True, activation=Tanh<>\n","      (activation): Tanh<>\n","      >\n","    (fc_w_t): Dense<input_channels=300, output_channels=2235>\n","    (fc_w_i): Dense<input_channels=2048, output_channels=2235>\n","    >\n","  (softmax): SoftmaxCrossEntropyWithLogits<>\n","  (acc): Accuracy<>\n","  >"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["load_checkpoint(train_config.checkpoint_path, net=network)\n","test_net = WithEvalCellWrapper(network, train_config)\n","test_net.set_train(False)"]},{"cell_type":"markdown","metadata":{},"source":["### 4.2 开始测试"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test(test_net, test_dataset):\n","\t# test\n","\tloss = []\n","\tacc = []\n","\tfor i in test_dataset.create_dict_iterator():\n","\t\tstep_loss, step_acc = test_net(i['image'], i['question'], i['answer'], i['options'])\n","\t\tloss.append(step_loss.item(0).asnumpy().item())\n","\t\tacc.append(step_acc.item(0).asnumpy().item())\n","\ttest_loss = sum(loss) / len(loss)\n","\ttest_acc = sum(acc) / len(acc)\n","\tprint('test loss =', test_loss, 'acc =', test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def test_feature_map(test_net, train_config, filter_dict):\n","\t# test\n","\tloss = []\n","\tacc = []\n","\tfor id in range(1, 14):\n","\t\tmox.file.copy_parallel(src_url= obs_path+train_config.train_featurerecord_path + \"test\" + str(id) + \".mindrecord\",    dst_url=train_config.train_featurerecord_path + \"test\" + str(id) + \".mindrecord\") \n","\t\tmox.file.copy_parallel(src_url= obs_path+train_config.train_featurerecord_path + \"test\" + str(id) + \".mindrecord.db\",    dst_url=train_config.train_featurerecord_path + \"test\" + str(id) + \".mindrecord.db\") \n","\t\ttest_dataset = generate_feature_map_dataset(train_config.train_featurerecord_path + 'test'+str(id)+'.mindrecord', train_config.batch_size, 1, train_config.max_length, filter_dict)\t\n","\t\tfor i in test_dataset.create_dict_iterator():\n","\t\t\tstep_loss, step_acc = test_net(i['image'], i['question'], i['answer'], i['options'])\n","\t\t\tloss.append(step_loss.item(0).asnumpy().item())\n","\t\t\tacc.append(step_acc.item(0).asnumpy().item())\n","\t\t# delete file\n","\t\ttry:\n","\t\t\tos.remove(train_config.train_featurerecord_path + \"test\" + str(id) + \".mindrecord\")\n","\t\t\tos.remove(train_config.train_featurerecord_path + \"test\" + str(id) + \".mindrecord.db\")\n","\t\t\tprint(\"-- delete file successfully!\")\n","\t\texcept(FileNotFoundError):\n","\t\t\tprint(\"-- file not exists!\")\n","   \n","\ttest_loss = sum(loss) / len(loss)\n","\ttest_acc = sum(acc) / len(acc)\n","\tprint('test loss =', test_loss, 'acc =', test_acc)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["test loss = 6.822631631798814 acc = 0.20789579967689822\n"]}],"source":["if config.use_pretrained_feature_map:\n","    test_feature_map(test_net, test_dataset)\n","else:\n","    test(test_net, train_config, filter_dict)"]}],"metadata":{"kernelspec":{"display_name":"Python 3.8.6 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.6"},"vscode":{"interpreter":{"hash":"3a53c88f4fdc719dd3265ddb13e8e9d7137a6cb76512705960f4604c66fa0a8c"}}},"nbformat":4,"nbformat_minor":4}
